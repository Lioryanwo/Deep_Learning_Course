{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7694ceff-a640-4967-bd24-e85630790faa",
   "metadata": {},
   "source": [
    "Libraries imports:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ed0b460f-5aa0-47a9-afc1-fdcafb086434",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Liory\\AppData\\Local\\Programs\\Python\\Python311\\python.exe\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'pip' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pip in c:\\users\\liory\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (25.3)\n",
      "Requirement already satisfied: torch in c:\\users\\liory\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (2.9.1)\n",
      "Requirement already satisfied: torchvision in c:\\users\\liory\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (0.24.1)\n",
      "Requirement already satisfied: torchaudio in c:\\users\\liory\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (2.9.1)\n",
      "Requirement already satisfied: filelock in c:\\users\\liory\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torch) (3.20.0)\n",
      "Requirement already satisfied: typing-extensions>=4.10.0 in c:\\users\\liory\\appdata\\roaming\\python\\python311\\site-packages (from torch) (4.15.0)\n",
      "Requirement already satisfied: sympy>=1.13.3 in c:\\users\\liory\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torch) (1.14.0)\n",
      "Requirement already satisfied: networkx>=2.5.1 in c:\\users\\liory\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torch) (3.6.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\liory\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torch) (3.1.6)\n",
      "Requirement already satisfied: fsspec>=0.8.5 in c:\\users\\liory\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torch) (2025.12.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\liory\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torchvision) (2.3.5)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\users\\liory\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from torchvision) (12.0.0)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\liory\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from sympy>=1.13.3->torch) (1.3.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\liory\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from jinja2->torch) (3.0.3)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\liory\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (3.10.8)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\liory\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib) (1.3.3)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\liory\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\liory\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib) (4.61.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\liory\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib) (1.4.9)\n",
      "Requirement already satisfied: numpy>=1.23 in c:\\users\\liory\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib) (2.3.5)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\liory\\appdata\\roaming\\python\\python311\\site-packages (from matplotlib) (25.0)\n",
      "Requirement already satisfied: pillow>=8 in c:\\users\\liory\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib) (12.0.0)\n",
      "Requirement already satisfied: pyparsing>=3 in c:\\users\\liory\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib) (3.2.5)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\liory\\appdata\\roaming\\python\\python311\\site-packages (from matplotlib) (2.9.0.post0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\liory\\appdata\\roaming\\python\\python311\\site-packages (from python-dateutil>=2.7->matplotlib) (1.17.0)\n",
      "Requirement already satisfied: numpy in c:\\users\\liory\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (2.3.5)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\liory\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (1.8.0)\n",
      "Requirement already satisfied: numpy>=1.24.1 in c:\\users\\liory\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from scikit-learn) (2.3.5)\n",
      "Requirement already satisfied: scipy>=1.10.0 in c:\\users\\liory\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from scikit-learn) (1.16.3)\n",
      "Requirement already satisfied: joblib>=1.3.0 in c:\\users\\liory\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from scikit-learn) (1.5.3)\n",
      "Requirement already satisfied: threadpoolctl>=3.2.0 in c:\\users\\liory\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from scikit-learn) (3.6.0)\n",
      "Requirement already satisfied: skorch in c:\\users\\liory\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (1.3.0)\n",
      "Requirement already satisfied: numpy>=1.13.3 in c:\\users\\liory\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from skorch) (2.3.5)\n",
      "Requirement already satisfied: scikit-learn>=0.22.0 in c:\\users\\liory\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from skorch) (1.8.0)\n",
      "Requirement already satisfied: scipy>=1.1.0 in c:\\users\\liory\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from skorch) (1.16.3)\n",
      "Requirement already satisfied: tabulate>=0.7.7 in c:\\users\\liory\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from skorch) (0.9.0)\n",
      "Requirement already satisfied: tqdm>=4.14.0 in c:\\users\\liory\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from skorch) (4.67.1)\n",
      "Requirement already satisfied: joblib>=1.3.0 in c:\\users\\liory\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from scikit-learn>=0.22.0->skorch) (1.5.3)\n",
      "Requirement already satisfied: threadpoolctl>=3.2.0 in c:\\users\\liory\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from scikit-learn>=0.22.0->skorch) (3.6.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\liory\\appdata\\roaming\\python\\python311\\site-packages (from tqdm>=4.14.0->skorch) (0.4.6)\n",
      "Requirement already satisfied: seaborn in c:\\users\\liory\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (0.13.2)\n",
      "Requirement already satisfied: numpy!=1.24.0,>=1.20 in c:\\users\\liory\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from seaborn) (2.3.5)\n",
      "Requirement already satisfied: pandas>=1.2 in c:\\users\\liory\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from seaborn) (2.3.3)\n",
      "Requirement already satisfied: matplotlib!=3.6.1,>=3.4 in c:\\users\\liory\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from seaborn) (3.10.8)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\liory\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (1.3.3)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\liory\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\liory\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (4.61.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\liory\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (1.4.9)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\liory\\appdata\\roaming\\python\\python311\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (25.0)\n",
      "Requirement already satisfied: pillow>=8 in c:\\users\\liory\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (12.0.0)\n",
      "Requirement already satisfied: pyparsing>=3 in c:\\users\\liory\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (3.2.5)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\liory\\appdata\\roaming\\python\\python311\\site-packages (from matplotlib!=3.6.1,>=3.4->seaborn) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\liory\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pandas>=1.2->seaborn) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\liory\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from pandas>=1.2->seaborn) (2025.3)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\liory\\appdata\\roaming\\python\\python311\\site-packages (from python-dateutil>=2.7->matplotlib!=3.6.1,>=3.4->seaborn) (1.17.0)\n",
      "2.9.1+cpu\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "print(sys.executable)\n",
    "!pip install -q skorch\n",
    "!python -m pip install --upgrade pip\n",
    "!python -m pip install torch torchvision torchaudio\n",
    "!python -m pip install matplotlib\n",
    "!python -m pip install numpy\n",
    "!python -m pip install scikit-learn\n",
    "!python -m pip install skorch\n",
    "!python -m pip install seaborn\n",
    "import torch\n",
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e485f618",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from skorch import NeuralNetClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "import seaborn as sns\n",
    "from skorch.helper import SliceDataset\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fb38188-a714-48e5-b3ef-557fafd36404",
   "metadata": {},
   "source": [
    "1+2. Data Preparation:\n",
    "I used the Fashion-MNIST dataset, a widely-used dataset of 70,000 28x28 grayscale image from 10 classes. The dataset is divided into 60,000 training images and 10,000 test images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "da0effa1-fbbc-4f33-b659-f0a36fe2859f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "img shape: torch.Size([1, 28, 28])\n",
      "label: 9\n",
      "train size: 60000 test size: 10000\n"
     ]
    }
   ],
   "source": [
    "# transforms: ToTensor + Normalize \n",
    "train_transform = transforms.Compose([\n",
    "    transforms.RandomHorizontalFlip(p=0.5),\n",
    "    transforms.RandomRotation(degrees=10),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,))\n",
    "])\n",
    "\n",
    "test_transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,))\n",
    "])\n",
    "\n",
    "## give to address a name:\n",
    "root_dir = r\"C:\\Users\\Liory\\Downloads\\Fashion-MNIST_Dataset\"\n",
    "\n",
    "## Load the FashionMNIST dataset\n",
    "train_dataset = datasets.FashionMNIST(root=root_dir, train=True, download=True, transform=train_transform)\n",
    "test_dataset = datasets.FashionMNIST(root=root_dir ,train=False ,download=True ,transform=test_transform)\n",
    "\n",
    "## Create DataLoader for batching\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "test_loader  = DataLoader(test_dataset,  batch_size=64, shuffle=False)\n",
    "\n",
    "# checking if this correct \n",
    "img, label = train_dataset[0]\n",
    "print(\"img shape:\", img.shape) \n",
    "torch.Size([1, 28, 28])\n",
    "print(\"label:\", label)\n",
    "print(\"train size:\", len(train_dataset), \"test size:\", len(test_dataset))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cc14137-3f8a-4792-b0df-fd8b376d5dd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def imshow(img):\n",
    "    img = img / 2 + 0.5       \n",
    "    npimg = img.numpy()\n",
    "\n",
    "    plt.figure(figsize=(8, 8))\n",
    "    plt.imshow(npimg[0], cmap='gray')  \n",
    "    plt.axis('off')\n",
    "    plt.show()\n",
    "\n",
    "    \n",
    "    # Get a batch of training images\n",
    "    dataiter = iter(train_loader)\n",
    "    images, labels = next(dataiter)\n",
    "    \n",
    "    # Show images in a grid\n",
    "    imshow(torchvision.utils.make_grid(images))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9bdb70f-70bf-4066-8060-cfaccb8e8e56",
   "metadata": {},
   "source": [
    "3. Model Building:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cdce5d4f-630a-4016-b101-447803331b6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape : torch.Size([4, 1, 28, 28])\n",
      "Output shape: torch.Size([4, 10])\n",
      "\n",
      "Weights: {'Conv1 Weights': 320, 'Conv2 Weights': 18496, 'FC1 Weights': 1606144, 'FC2 Weights': 5130, 'Total Weights (manual)': 1630090, 'Total Params (pytorch)': 1630090}\n"
     ]
    }
   ],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self, dropout=0.3):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 32, kernel_size=3, stride=1, padding=1)\n",
    "        self.pool  = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.fc1 = nn.Linear(64 * 7 * 7, 512)\n",
    "        self.fc2 = nn.Linear(512, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(torch.relu(self.conv1(x)))  # [B,32,14,14]\n",
    "        x = self.pool(torch.relu(self.conv2(x)))  # [B,64,7,7]\n",
    "        x = x.view(x.size(0), -1)                 # [B, 64*7*7]\n",
    "        x = self.dropout(x)\n",
    "        x = torch.relu(self.fc1(x))               # [B,512]\n",
    "        x = self.fc2(x)                           # [B,10] logits\n",
    "        return x\n",
    "\n",
    "\n",
    "def count_params(m: nn.Module) -> int:\n",
    "    return sum(p.numel() for p in m.parameters())\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    model = CNN(dropout=0.3)\n",
    "\n",
    "    x = torch.randn(4, 1, 28, 28)  # batch=4, grayscale, 28x28\n",
    "    y = model(x)\n",
    "    print(\"Input shape :\", x.shape)\n",
    "    print(\"Output shape:\", y.shape)  \n",
    "\n",
    "    # Conv1: out=32, in=1, k=3x3 + bias per out channel\n",
    "    conv1_total = (32 * 1 * 3 * 3) + 32\n",
    "\n",
    "    # Conv2: out=64, in=32, k=3x3 + bias\n",
    "    conv2_total = (64 * 32 * 3 * 3) + 64\n",
    "\n",
    "    # FC1: out=512, in=64*7*7 + bias\n",
    "    fc1_in = 64 * 7 * 7\n",
    "    fc1_total = (512 * fc1_in) + 512\n",
    "\n",
    "    # FC2: out=10, in=512 + bias\n",
    "    fc2_total = (10 * 512) + 10\n",
    "\n",
    "    total_manual = conv1_total + conv2_total + fc1_total + fc2_total\n",
    "\n",
    "    weights = {\n",
    "        \"Conv1 Weights\": conv1_total,\n",
    "        \"Conv2 Weights\": conv2_total,\n",
    "        \"FC1 Weights\": fc1_total,\n",
    "        \"FC2 Weights\": fc2_total,\n",
    "        \"Total Weights (manual)\": total_manual,\n",
    "        \"Total Params (pytorch)\": count_params(model),\n",
    "    }\n",
    "\n",
    "    print(\"\\nWeights:\", weights)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "262b4d6e-ecce-4a04-a96a-847e86552221",
   "metadata": {},
   "source": [
    "4. Training:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61370592-05f5-491b-910c-3ccc260a1fb2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/12, Train Loss: 0.7229, Val Loss: 0.4822\n",
      "Epoch 3/12, Train Loss: 0.4493, Val Loss: 0.3527\n",
      "Epoch 5/12, Train Loss: 0.3912, Val Loss: 0.3241\n",
      "Epoch 7/12, Train Loss: 0.3664, Val Loss: 0.2985\n",
      "Epoch 9/12, Train Loss: 0.3477, Val Loss: 0.2875\n",
      "Epoch 11/12, Train Loss: 0.3364, Val Loss: 0.2796\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## ---------- Updated transformations with data augmentation ----------\n",
    "transform_train = transforms.Compose([\n",
    "    transforms.RandomCrop(28, padding=4),   \n",
    "    transforms.RandomRotation(15),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,))\n",
    "])\n",
    "\n",
    "transform_test = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,))\n",
    "])\n",
    "\n",
    "## ---------- Datasets + Loaders ----------\n",
    "root_dir = r\"C:\\Users\\Liory\\Downloads\\Fashion-MNIST_Dataset\"\n",
    "\n",
    "train_dataset = datasets.FashionMNIST(root=root_dir, train=True,  download=True, transform=transform_train)\n",
    "test_dataset  = datasets.FashionMNIST(root=root_dir, train=False, download=True, transform=transform_test)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "test_loader  = DataLoader(test_dataset,  batch_size=64, shuffle=False)\n",
    "\n",
    "## ---------- Model ----------\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self, dropout=0.3):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 32, kernel_size=3, stride=1, padding=1)\n",
    "        self.pool  = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, stride=1, padding=1)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.fc1 = nn.Linear(64 * 7 * 7, 512)   # 28->14->7\n",
    "        self.fc2 = nn.Linear(512, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(torch.relu(self.conv1(x)))  # [B,32,14,14]\n",
    "        x = self.pool(torch.relu(self.conv2(x)))  # [B,64,7,7]\n",
    "        x = x.view(x.size(0), -1)                 # [B,64*7*7]\n",
    "        x = self.dropout(x)\n",
    "        x = torch.relu(self.fc1(x))               # [B,512]\n",
    "        x = self.fc2(x)                           # [B,10] logits\n",
    "        return x\n",
    "\n",
    "model = CNN()\n",
    "\n",
    "## ---------- Loss + Optimizer ----------\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "## ---------- Training loop ----------\n",
    "num_epochs = 12\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "\n",
    "for epoch in range(num_epochs): \n",
    "    running_loss = 0.0\n",
    "    model.train()\n",
    "\n",
    "    for inputs, labels in train_loader:\n",
    "        optimizer.zero_grad()        \n",
    "        outputs = model(inputs)       \n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()             \n",
    "        running_loss += loss.item()\n",
    "\n",
    "    # Validation phase \n",
    "    if epoch % 2 == 0:\n",
    "        train_loss = running_loss / len(train_loader)\n",
    "        train_losses.append(train_loss)\n",
    "\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        with torch.no_grad():\n",
    "            for inputs, labels in test_loader:\n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, labels)\n",
    "                val_loss += loss.item()\n",
    "\n",
    "        val_loss = val_loss / len(test_loader)\n",
    "        val_losses.append(val_loss)\n",
    "\n",
    "        print(f\"Epoch {epoch+1}/{num_epochs}, Train Loss: {train_loss:.4f}, Val Loss: {val_loss:.4f}\")\n",
    "\n",
    "## ---------- Visualization Plot ----------\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(range(1, len(train_losses) + 1), train_losses, label='Training Loss')\n",
    "plt.plot(range(1, len(val_losses) + 1), val_losses, label='Validation Loss')\n",
    "plt.xlabel('Validation Steps (every 2 epochs)')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0461ec6-af21-40de-93d4-3219549380cf",
   "metadata": {},
   "source": [
    "5. Evaluation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4b2fc5ff-66bf-4f59-a975-4ef63d1aa316",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 90.09%\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "all_preds = []\n",
    "all_labels = []\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():       \n",
    "    for inputs, labels in test_loader:\n",
    "        outputs = model(inputs)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "        all_preds.extend(predicted.cpu().numpy())\n",
    "        all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "accuracy = 100 * correct / total\n",
    "print(f\"Test Accuracy: {accuracy:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50744548-d3d6-4ad0-8a42-3c093aea3d3c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f13ea914-ff33-48ca-bce1-3c2dc00a1c04",
   "metadata": {},
   "source": [
    "6. Visualization:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fb98357-f6ed-42fe-878a-a7f58c7928a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x400 with 32 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def visualize_filters(layer):\n",
    "    filters = layer.weight.data.clone() \n",
    "\n",
    "    #  \n",
    "    filters = filters - filters.min()\n",
    "    filters = filters / filters.max()\n",
    "\n",
    "    filter_num = filters.shape[0]\n",
    "    n_columns = 8\n",
    "    n_rows = filter_num // n_columns + (filter_num % n_columns > 0)\n",
    "\n",
    "    fig, axs = plt.subplots(n_rows, n_columns, figsize=(n_columns, n_rows))\n",
    "\n",
    "    for i in range(filter_num):\n",
    "        row = i // n_columns\n",
    "        col = i % n_columns\n",
    "        axs[row, col].imshow(filters[i, 0], cmap='gray')\n",
    "        axs[row, col].axis('off')\n",
    "\n",
    "    plt.suptitle(\"Learned Filters (Conv1)\")\n",
    "    plt.show()\n",
    "\n",
    "model = CNN()\n",
    "visualize_filters(model.conv1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "72d9534f-bb9c-46e2-82e0-4da501ac6989",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_intermediate_layers(image, model):\n",
    "    model.eval()\n",
    "\n",
    "    activations = []\n",
    "\n",
    "    x = image.unsqueeze(0)\n",
    "\n",
    "    # ----- Conv1 -----\n",
    "    x = model.conv1(x)\n",
    "    x = torch.relu(x)\n",
    "    activations.append(x)   \n",
    "    x = model.pool(x)\n",
    "\n",
    "    # ----- Conv2 -----\n",
    "    x = model.conv2(x)\n",
    "    x = torch.relu(x)\n",
    "    activations.append(x)  \n",
    "    x = model.pool(x)\n",
    "\n",
    "    # ----- Visualization -----\n",
    "    for idx, activation in enumerate(activations):\n",
    "        feature_maps = activation.detach().squeeze(0)  \n",
    "        num_maps = feature_maps.shape[0]\n",
    "\n",
    "        n_columns = 8\n",
    "        n_rows = num_maps // n_columns + (num_maps % n_columns > 0)\n",
    "\n",
    "        fig, axs = plt.subplots(n_rows, n_columns, figsize=(15, 8))\n",
    "        fig.suptitle(f'Feature Maps after Conv Layer {idx + 1}')\n",
    "\n",
    "        for i in range(num_maps):\n",
    "            row = i // n_columns\n",
    "            col = i % n_columns\n",
    "            axs[row, col].imshow(feature_maps[i], cmap='gray')\n",
    "            axs[row, col].axis('off')\n",
    "\n",
    "        plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac9db662-d735-4473-9a5e-118dc89a1513",
   "metadata": {},
   "source": [
    "7. Hyperparameter Tuning:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9d54612-8cb0-4b15-aa6b-1bf6a3905133",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  epoch    train_loss    valid_acc    valid_loss      dur\n",
      "-------  ------------  -----------  ------------  -------\n",
      "      1        \u001b[36m0.8110\u001b[0m       \u001b[32m0.7614\u001b[0m        \u001b[35m0.6237\u001b[0m  21.9766\n",
      "      2        \u001b[36m0.5714\u001b[0m       \u001b[32m0.7929\u001b[0m        \u001b[35m0.5445\u001b[0m  23.2888\n",
      "      3        \u001b[36m0.4986\u001b[0m       \u001b[32m0.8267\u001b[0m        \u001b[35m0.4603\u001b[0m  24.0143\n",
      "      4        \u001b[36m0.4575\u001b[0m       \u001b[32m0.8387\u001b[0m        \u001b[35m0.4328\u001b[0m  24.2041\n",
      "      5        \u001b[36m0.4276\u001b[0m       \u001b[32m0.8576\u001b[0m        \u001b[35m0.3872\u001b[0m  24.1553\n",
      "  epoch    train_loss    valid_acc    valid_loss      dur\n",
      "-------  ------------  -----------  ------------  -------\n",
      "      1        \u001b[36m0.7981\u001b[0m       \u001b[32m0.7671\u001b[0m        \u001b[35m0.6040\u001b[0m  22.4145\n",
      "      2        \u001b[36m0.5671\u001b[0m       \u001b[32m0.8135\u001b[0m        \u001b[35m0.4869\u001b[0m  24.1288\n",
      "      3        \u001b[36m0.4956\u001b[0m       \u001b[32m0.8215\u001b[0m        \u001b[35m0.4674\u001b[0m  23.6906\n",
      "      4        \u001b[36m0.4519\u001b[0m       \u001b[32m0.8459\u001b[0m        \u001b[35m0.4190\u001b[0m  23.8128\n",
      "      5        \u001b[36m0.4202\u001b[0m       \u001b[32m0.8536\u001b[0m        \u001b[35m0.3957\u001b[0m  23.7590\n",
      "  epoch    train_loss    valid_acc    valid_loss      dur\n",
      "-------  ------------  -----------  ------------  -------\n",
      "      1        \u001b[36m0.8023\u001b[0m       \u001b[32m0.7784\u001b[0m        \u001b[35m0.6058\u001b[0m  22.0408\n",
      "      2        \u001b[36m0.5688\u001b[0m       \u001b[32m0.8057\u001b[0m        \u001b[35m0.5234\u001b[0m  23.6222\n",
      "      3        \u001b[36m0.5047\u001b[0m       \u001b[32m0.8296\u001b[0m        \u001b[35m0.4470\u001b[0m  23.5577\n",
      "      4        \u001b[36m0.4633\u001b[0m       \u001b[32m0.8351\u001b[0m        \u001b[35m0.4404\u001b[0m  23.8281\n",
      "      5        \u001b[36m0.4311\u001b[0m       \u001b[32m0.8499\u001b[0m        \u001b[35m0.4096\u001b[0m  23.7667\n",
      "  epoch    train_loss    valid_acc    valid_loss      dur\n",
      "-------  ------------  -----------  ------------  -------\n",
      "      1        \u001b[36m0.8135\u001b[0m       \u001b[32m0.7574\u001b[0m        \u001b[35m0.6454\u001b[0m  22.8505\n",
      "      2        \u001b[36m0.5888\u001b[0m       \u001b[32m0.7986\u001b[0m        \u001b[35m0.5191\u001b[0m  22.9766\n",
      "      3        \u001b[36m0.5180\u001b[0m       \u001b[32m0.8086\u001b[0m        \u001b[35m0.5037\u001b[0m  23.5406\n",
      "      4        \u001b[36m0.4766\u001b[0m       \u001b[32m0.8277\u001b[0m        \u001b[35m0.4560\u001b[0m  52.9111\n",
      "      5        \u001b[36m0.4466\u001b[0m       \u001b[32m0.8406\u001b[0m        \u001b[35m0.4317\u001b[0m  65.2145\n",
      "  epoch    train_loss    valid_acc    valid_loss      dur\n",
      "-------  ------------  -----------  ------------  -------\n",
      "      1        \u001b[36m0.8081\u001b[0m       \u001b[32m0.7554\u001b[0m        \u001b[35m0.6425\u001b[0m  22.2095\n",
      "      2        \u001b[36m0.5939\u001b[0m       \u001b[32m0.8036\u001b[0m        \u001b[35m0.5256\u001b[0m  23.0318\n",
      "      3        \u001b[36m0.5240\u001b[0m       \u001b[32m0.8113\u001b[0m        \u001b[35m0.4896\u001b[0m  23.5638\n",
      "      4        \u001b[36m0.4788\u001b[0m       \u001b[32m0.8296\u001b[0m        \u001b[35m0.4589\u001b[0m  56.1179\n",
      "      5        \u001b[36m0.4539\u001b[0m       \u001b[32m0.8360\u001b[0m        \u001b[35m0.4315\u001b[0m  60.1705\n",
      "  epoch    train_loss    valid_acc    valid_loss      dur\n",
      "-------  ------------  -----------  ------------  -------\n",
      "      1        \u001b[36m0.8034\u001b[0m       \u001b[32m0.7584\u001b[0m        \u001b[35m0.6269\u001b[0m  22.1420\n",
      "      2        \u001b[36m0.5813\u001b[0m       \u001b[32m0.8175\u001b[0m        \u001b[35m0.5112\u001b[0m  23.2167\n",
      "      3        \u001b[36m0.5140\u001b[0m       \u001b[32m0.8305\u001b[0m        \u001b[35m0.4582\u001b[0m  23.6502\n",
      "      4        \u001b[36m0.4751\u001b[0m       \u001b[32m0.8345\u001b[0m        \u001b[35m0.4377\u001b[0m  53.7258\n",
      "      5        \u001b[36m0.4472\u001b[0m       \u001b[32m0.8481\u001b[0m        \u001b[35m0.4011\u001b[0m  57.3089\n",
      "  epoch    train_loss    valid_acc    valid_loss      dur\n",
      "-------  ------------  -----------  ------------  -------\n",
      "      1        \u001b[36m2.2674\u001b[0m       \u001b[32m0.2510\u001b[0m        \u001b[35m2.2186\u001b[0m  19.7646\n",
      "      2        \u001b[36m2.1483\u001b[0m       \u001b[32m0.4126\u001b[0m        \u001b[35m2.0293\u001b[0m  21.0819\n",
      "      3        \u001b[36m1.8678\u001b[0m       \u001b[32m0.4869\u001b[0m        \u001b[35m1.6707\u001b[0m  20.9249\n",
      "      4        \u001b[36m1.5490\u001b[0m       \u001b[32m0.5146\u001b[0m        \u001b[35m1.4425\u001b[0m  21.1025\n",
      "      5        \u001b[36m1.3896\u001b[0m       \u001b[32m0.5406\u001b[0m        \u001b[35m1.3081\u001b[0m  20.9799\n",
      "  epoch    train_loss    valid_acc    valid_loss      dur\n",
      "-------  ------------  -----------  ------------  -------\n",
      "      1        \u001b[36m2.2820\u001b[0m       \u001b[32m0.2085\u001b[0m        \u001b[35m2.2559\u001b[0m  20.0217\n",
      "      2        \u001b[36m2.2267\u001b[0m       \u001b[32m0.2853\u001b[0m        \u001b[35m2.1783\u001b[0m  21.0765\n",
      "      3        \u001b[36m2.1076\u001b[0m       \u001b[32m0.3976\u001b[0m        \u001b[35m1.9989\u001b[0m  21.1150\n",
      "      4        \u001b[36m1.8671\u001b[0m       \u001b[32m0.4743\u001b[0m        \u001b[35m1.7052\u001b[0m  21.2654\n",
      "      5        \u001b[36m1.5996\u001b[0m       \u001b[32m0.5068\u001b[0m        \u001b[35m1.4799\u001b[0m  20.9570\n",
      "  epoch    train_loss    valid_acc    valid_loss      dur\n",
      "-------  ------------  -----------  ------------  -------\n",
      "      1        \u001b[36m2.2813\u001b[0m       \u001b[32m0.2504\u001b[0m        \u001b[35m2.2477\u001b[0m  20.0481\n",
      "      2        \u001b[36m2.2052\u001b[0m       \u001b[32m0.3476\u001b[0m        \u001b[35m2.1311\u001b[0m  21.2500\n",
      "      3        \u001b[36m2.0269\u001b[0m       \u001b[32m0.4634\u001b[0m        \u001b[35m1.8670\u001b[0m  21.1614\n",
      "      4        \u001b[36m1.7325\u001b[0m       \u001b[32m0.5008\u001b[0m        \u001b[35m1.5756\u001b[0m  21.0081\n",
      "      5        \u001b[36m1.5034\u001b[0m       \u001b[32m0.5292\u001b[0m        \u001b[35m1.3813\u001b[0m  21.1570\n",
      "  epoch    train_loss    valid_acc    valid_loss      dur\n",
      "-------  ------------  -----------  ------------  -------\n",
      "      1        \u001b[36m2.2742\u001b[0m       \u001b[32m0.3844\u001b[0m        \u001b[35m2.2378\u001b[0m  20.8367\n",
      "      2        \u001b[36m2.1882\u001b[0m       \u001b[32m0.4168\u001b[0m        \u001b[35m2.1091\u001b[0m  22.0007\n",
      "      3        \u001b[36m2.0024\u001b[0m       \u001b[32m0.4431\u001b[0m        \u001b[35m1.8604\u001b[0m  21.5999\n",
      "      4        \u001b[36m1.7285\u001b[0m       \u001b[32m0.4880\u001b[0m        \u001b[35m1.5863\u001b[0m  21.6542\n",
      "      5        \u001b[36m1.5004\u001b[0m       \u001b[32m0.5260\u001b[0m        \u001b[35m1.4114\u001b[0m  21.5773\n",
      "  epoch    train_loss    valid_acc    valid_loss      dur\n",
      "-------  ------------  -----------  ------------  -------\n",
      "      1        \u001b[36m2.2661\u001b[0m       \u001b[32m0.3409\u001b[0m        \u001b[35m2.2174\u001b[0m  20.8674\n",
      "      2        \u001b[36m2.1485\u001b[0m       \u001b[32m0.4214\u001b[0m        \u001b[35m2.0295\u001b[0m  21.6850\n",
      "      3        \u001b[36m1.8832\u001b[0m       \u001b[32m0.4796\u001b[0m        \u001b[35m1.6928\u001b[0m  21.7650\n",
      "      4        \u001b[36m1.5863\u001b[0m       \u001b[32m0.5164\u001b[0m        \u001b[35m1.4506\u001b[0m  21.6176\n",
      "      5        \u001b[36m1.4191\u001b[0m       \u001b[32m0.5309\u001b[0m        \u001b[35m1.3305\u001b[0m  21.6473\n",
      "  epoch    train_loss    valid_acc    valid_loss      dur\n",
      "-------  ------------  -----------  ------------  -------\n",
      "      1        \u001b[36m2.2896\u001b[0m       \u001b[32m0.2001\u001b[0m        \u001b[35m2.2633\u001b[0m  21.2906\n",
      "      2        \u001b[36m2.2381\u001b[0m       \u001b[32m0.3118\u001b[0m        \u001b[35m2.1928\u001b[0m  21.9489\n",
      "      3        \u001b[36m2.1369\u001b[0m       \u001b[32m0.3752\u001b[0m        \u001b[35m2.0408\u001b[0m  21.4008\n",
      "      4        \u001b[36m1.9304\u001b[0m       \u001b[32m0.4606\u001b[0m        \u001b[35m1.7705\u001b[0m  21.7674\n",
      "      5        \u001b[36m1.6642\u001b[0m       \u001b[32m0.4953\u001b[0m        \u001b[35m1.5297\u001b[0m  23.2933\n",
      "  epoch    train_loss    valid_acc    valid_loss      dur\n",
      "-------  ------------  -----------  ------------  -------\n",
      "      1        \u001b[36m0.8266\u001b[0m       \u001b[32m0.7534\u001b[0m        \u001b[35m0.6393\u001b[0m  23.0377\n",
      "      2        \u001b[36m0.5973\u001b[0m       \u001b[32m0.7924\u001b[0m        \u001b[35m0.5408\u001b[0m  24.3110\n",
      "      3        \u001b[36m0.5282\u001b[0m       \u001b[32m0.7970\u001b[0m        \u001b[35m0.5342\u001b[0m  24.4595\n",
      "      4        \u001b[36m0.4883\u001b[0m       \u001b[32m0.8385\u001b[0m        \u001b[35m0.4446\u001b[0m  24.6286\n",
      "      5        \u001b[36m0.4540\u001b[0m       \u001b[32m0.8426\u001b[0m        \u001b[35m0.4188\u001b[0m  24.7693\n",
      "  epoch    train_loss    valid_acc    valid_loss      dur\n",
      "-------  ------------  -----------  ------------  -------\n",
      "      1        \u001b[36m0.8240\u001b[0m       \u001b[32m0.7696\u001b[0m        \u001b[35m0.6087\u001b[0m  22.2573\n",
      "      2        \u001b[36m0.5951\u001b[0m       \u001b[32m0.7947\u001b[0m        \u001b[35m0.5208\u001b[0m  23.9061\n",
      "      3        \u001b[36m0.5224\u001b[0m       \u001b[32m0.8231\u001b[0m        \u001b[35m0.4561\u001b[0m  23.5317\n",
      "      4        \u001b[36m0.4837\u001b[0m       \u001b[32m0.8356\u001b[0m        \u001b[35m0.4504\u001b[0m  24.2093\n",
      "      5        \u001b[36m0.4531\u001b[0m       \u001b[32m0.8585\u001b[0m        \u001b[35m0.3951\u001b[0m  22.9502\n",
      "  epoch    train_loss    valid_acc    valid_loss      dur\n",
      "-------  ------------  -----------  ------------  -------\n",
      "      1        \u001b[36m0.8194\u001b[0m       \u001b[32m0.7770\u001b[0m        \u001b[35m0.5895\u001b[0m  21.4850\n",
      "      2        \u001b[36m0.5847\u001b[0m       \u001b[32m0.8009\u001b[0m        \u001b[35m0.5202\u001b[0m  22.9257\n",
      "      3        \u001b[36m0.5270\u001b[0m       \u001b[32m0.8205\u001b[0m        \u001b[35m0.4683\u001b[0m  23.3234\n",
      "      4        \u001b[36m0.4767\u001b[0m       \u001b[32m0.8321\u001b[0m        \u001b[35m0.4392\u001b[0m  22.9047\n",
      "      5        \u001b[36m0.4491\u001b[0m       \u001b[32m0.8514\u001b[0m        \u001b[35m0.3959\u001b[0m  23.3092\n",
      "  epoch    train_loss    valid_acc    valid_loss      dur\n",
      "-------  ------------  -----------  ------------  -------\n",
      "      1        \u001b[36m0.8336\u001b[0m       \u001b[32m0.7428\u001b[0m        \u001b[35m0.6620\u001b[0m  21.1466\n",
      "      2        \u001b[36m0.6045\u001b[0m       \u001b[32m0.7963\u001b[0m        \u001b[35m0.5338\u001b[0m  22.0676\n",
      "      3        \u001b[36m0.5443\u001b[0m       \u001b[32m0.8150\u001b[0m        \u001b[35m0.4968\u001b[0m  23.3577\n",
      "      4        \u001b[36m0.5039\u001b[0m       \u001b[32m0.8269\u001b[0m        \u001b[35m0.4669\u001b[0m  47.9031\n",
      "      5        \u001b[36m0.4742\u001b[0m       \u001b[32m0.8491\u001b[0m        \u001b[35m0.4148\u001b[0m  55.8277\n",
      "  epoch    train_loss    valid_acc    valid_loss      dur\n",
      "-------  ------------  -----------  ------------  -------\n",
      "      1        \u001b[36m0.8168\u001b[0m       \u001b[32m0.7594\u001b[0m        \u001b[35m0.6307\u001b[0m  21.6899\n",
      "      2        \u001b[36m0.6004\u001b[0m       \u001b[32m0.7960\u001b[0m        \u001b[35m0.5244\u001b[0m  22.1099\n",
      "      3        \u001b[36m0.5351\u001b[0m       \u001b[32m0.8106\u001b[0m        \u001b[35m0.5055\u001b[0m  24.1709\n",
      "      4        \u001b[36m0.4959\u001b[0m       \u001b[32m0.8410\u001b[0m        \u001b[35m0.4361\u001b[0m  45.8631\n",
      "      5        \u001b[36m0.4699\u001b[0m       \u001b[32m0.8411\u001b[0m        \u001b[35m0.4269\u001b[0m  49.3412\n",
      "  epoch    train_loss    valid_acc    valid_loss      dur\n",
      "-------  ------------  -----------  ------------  -------\n",
      "      1        \u001b[36m0.8295\u001b[0m       \u001b[32m0.7664\u001b[0m        \u001b[35m0.6192\u001b[0m  21.9030\n",
      "      2        \u001b[36m0.6064\u001b[0m       \u001b[32m0.7971\u001b[0m        \u001b[35m0.5198\u001b[0m  22.5586\n",
      "      3        \u001b[36m0.5343\u001b[0m       \u001b[32m0.8254\u001b[0m        \u001b[35m0.4734\u001b[0m  23.2889\n",
      "      4        \u001b[36m0.4913\u001b[0m       \u001b[32m0.8425\u001b[0m        \u001b[35m0.4368\u001b[0m  45.8440\n",
      "      5        \u001b[36m0.4687\u001b[0m       \u001b[32m0.8480\u001b[0m        \u001b[35m0.4119\u001b[0m  60.6813\n",
      "  epoch    train_loss    valid_acc    valid_loss      dur\n",
      "-------  ------------  -----------  ------------  -------\n",
      "      1        \u001b[36m2.2830\u001b[0m       \u001b[32m0.2914\u001b[0m        \u001b[35m2.2524\u001b[0m  20.0009\n",
      "      2        \u001b[36m2.2201\u001b[0m       \u001b[32m0.3490\u001b[0m        \u001b[35m2.1567\u001b[0m  20.8030\n",
      "      3        \u001b[36m2.0795\u001b[0m       \u001b[32m0.4256\u001b[0m        \u001b[35m1.9431\u001b[0m  20.4640\n",
      "      4        \u001b[36m1.8192\u001b[0m       \u001b[32m0.4703\u001b[0m        \u001b[35m1.6651\u001b[0m  20.7352\n",
      "      5        \u001b[36m1.5718\u001b[0m       \u001b[32m0.5046\u001b[0m        \u001b[35m1.4679\u001b[0m  20.4701\n",
      "  epoch    train_loss    valid_acc    valid_loss      dur\n",
      "-------  ------------  -----------  ------------  -------\n",
      "      1        \u001b[36m2.2861\u001b[0m       \u001b[32m0.2771\u001b[0m        \u001b[35m2.2587\u001b[0m  19.5681\n",
      "      2        \u001b[36m2.2337\u001b[0m       \u001b[32m0.3668\u001b[0m        \u001b[35m2.1798\u001b[0m  20.9344\n",
      "      3        \u001b[36m2.1204\u001b[0m       \u001b[32m0.3997\u001b[0m        \u001b[35m2.0030\u001b[0m  20.8351\n",
      "      4        \u001b[36m1.8948\u001b[0m       \u001b[32m0.4825\u001b[0m        \u001b[35m1.7212\u001b[0m  20.8914\n",
      "      5        \u001b[36m1.6295\u001b[0m       \u001b[32m0.5195\u001b[0m        \u001b[35m1.4770\u001b[0m  20.4104\n",
      "  epoch    train_loss    valid_acc    valid_loss      dur\n",
      "-------  ------------  -----------  ------------  -------\n",
      "      1        \u001b[36m2.2864\u001b[0m       \u001b[32m0.2893\u001b[0m        \u001b[35m2.2550\u001b[0m  19.4793\n",
      "      2        \u001b[36m2.2266\u001b[0m       \u001b[32m0.3718\u001b[0m        \u001b[35m2.1615\u001b[0m  20.3372\n",
      "      3        \u001b[36m2.0907\u001b[0m       \u001b[32m0.4236\u001b[0m        \u001b[35m1.9513\u001b[0m  19.7253\n",
      "      4        \u001b[36m1.8401\u001b[0m       \u001b[32m0.4667\u001b[0m        \u001b[35m1.6609\u001b[0m  19.3513\n",
      "      5        \u001b[36m1.5943\u001b[0m       \u001b[32m0.5016\u001b[0m        \u001b[35m1.4572\u001b[0m  18.5151\n",
      "  epoch    train_loss    valid_acc    valid_loss      dur\n",
      "-------  ------------  -----------  ------------  -------\n",
      "      1        \u001b[36m2.2881\u001b[0m       \u001b[32m0.2981\u001b[0m        \u001b[35m2.2657\u001b[0m  18.4245\n",
      "      2        \u001b[36m2.2419\u001b[0m       \u001b[32m0.3660\u001b[0m        \u001b[35m2.1968\u001b[0m  19.5374\n",
      "      3        \u001b[36m2.1450\u001b[0m       \u001b[32m0.3996\u001b[0m        \u001b[35m2.0492\u001b[0m  19.4338\n",
      "      4        \u001b[36m1.9505\u001b[0m       \u001b[32m0.4391\u001b[0m        \u001b[35m1.8076\u001b[0m  19.1505\n",
      "      5        \u001b[36m1.7003\u001b[0m       \u001b[32m0.4894\u001b[0m        \u001b[35m1.5793\u001b[0m  18.6520\n",
      "  epoch    train_loss    valid_acc    valid_loss      dur\n",
      "-------  ------------  -----------  ------------  -------\n",
      "      1        \u001b[36m2.2880\u001b[0m       \u001b[32m0.2599\u001b[0m        \u001b[35m2.2636\u001b[0m  18.5363\n",
      "      2        \u001b[36m2.2421\u001b[0m       \u001b[32m0.3190\u001b[0m        \u001b[35m2.1932\u001b[0m  19.3052\n",
      "      3        \u001b[36m2.1372\u001b[0m       \u001b[32m0.3836\u001b[0m        \u001b[35m2.0252\u001b[0m  19.3406\n",
      "      4        \u001b[36m1.9145\u001b[0m       \u001b[32m0.4575\u001b[0m        \u001b[35m1.7419\u001b[0m  19.6516\n",
      "      5        \u001b[36m1.6485\u001b[0m       \u001b[32m0.5009\u001b[0m        \u001b[35m1.4978\u001b[0m  18.7745\n",
      "  epoch    train_loss    valid_acc    valid_loss      dur\n",
      "-------  ------------  -----------  ------------  -------\n",
      "      1        \u001b[36m2.2971\u001b[0m       \u001b[32m0.2581\u001b[0m        \u001b[35m2.2840\u001b[0m  18.1519\n",
      "      2        \u001b[36m2.2753\u001b[0m       \u001b[32m0.3906\u001b[0m        \u001b[35m2.2553\u001b[0m  19.6302\n",
      "      3        \u001b[36m2.2417\u001b[0m       \u001b[32m0.4432\u001b[0m        \u001b[35m2.2078\u001b[0m  19.2167\n",
      "      4        \u001b[36m2.1776\u001b[0m       \u001b[32m0.4502\u001b[0m        \u001b[35m2.1115\u001b[0m  19.0946\n",
      "      5        \u001b[36m2.0477\u001b[0m       \u001b[32m0.4582\u001b[0m        \u001b[35m1.9240\u001b[0m  18.8970\n",
      "  epoch    train_loss    valid_acc    valid_loss      dur\n",
      "-------  ------------  -----------  ------------  -------\n",
      "      1        \u001b[36m0.8182\u001b[0m       \u001b[32m0.7341\u001b[0m        \u001b[35m0.6588\u001b[0m  20.1609\n",
      "      2        \u001b[36m0.5820\u001b[0m       \u001b[32m0.7963\u001b[0m        \u001b[35m0.5389\u001b[0m  22.3504\n",
      "      3        \u001b[36m0.5080\u001b[0m       \u001b[32m0.8260\u001b[0m        \u001b[35m0.4745\u001b[0m  22.2268\n",
      "      4        \u001b[36m0.4609\u001b[0m       \u001b[32m0.8346\u001b[0m        \u001b[35m0.4429\u001b[0m  22.7683\n",
      "      5        \u001b[36m0.4363\u001b[0m       \u001b[32m0.8525\u001b[0m        \u001b[35m0.4025\u001b[0m  23.4783\n",
      "      6        \u001b[36m0.4129\u001b[0m       0.8452        0.4097  22.6836\n",
      "      7        \u001b[36m0.3994\u001b[0m       \u001b[32m0.8598\u001b[0m        \u001b[35m0.3721\u001b[0m  22.6426\n",
      "      8        \u001b[36m0.3828\u001b[0m       \u001b[32m0.8602\u001b[0m        0.3858  22.6244\n",
      "  epoch    train_loss    valid_acc    valid_loss      dur\n",
      "-------  ------------  -----------  ------------  -------\n",
      "      1        \u001b[36m0.8025\u001b[0m       \u001b[32m0.7850\u001b[0m        \u001b[35m0.5886\u001b[0m  20.0773\n",
      "      2        \u001b[36m0.5688\u001b[0m       \u001b[32m0.8139\u001b[0m        \u001b[35m0.4966\u001b[0m  23.1496\n",
      "      3        \u001b[36m0.4967\u001b[0m       \u001b[32m0.8366\u001b[0m        \u001b[35m0.4419\u001b[0m  36.8173\n",
      "      4        \u001b[36m0.4554\u001b[0m       \u001b[32m0.8459\u001b[0m        \u001b[35m0.4081\u001b[0m  44.6709\n",
      "      5        \u001b[36m0.4249\u001b[0m       \u001b[32m0.8531\u001b[0m        \u001b[35m0.4040\u001b[0m  44.9457\n",
      "      6        \u001b[36m0.4006\u001b[0m       \u001b[32m0.8599\u001b[0m        \u001b[35m0.3754\u001b[0m  43.8086\n",
      "      7        \u001b[36m0.3929\u001b[0m       \u001b[32m0.8672\u001b[0m        \u001b[35m0.3534\u001b[0m  44.7884\n",
      "      8        \u001b[36m0.3746\u001b[0m       0.8641        0.3610  43.8804\n",
      "  epoch    train_loss    valid_acc    valid_loss      dur\n",
      "-------  ------------  -----------  ------------  -------\n",
      "      1        \u001b[36m0.8086\u001b[0m       \u001b[32m0.7769\u001b[0m        \u001b[35m0.5856\u001b[0m  41.2438\n",
      "      2        \u001b[36m0.5829\u001b[0m       \u001b[32m0.8111\u001b[0m        \u001b[35m0.5032\u001b[0m  44.5812\n",
      "      3        \u001b[36m0.5094\u001b[0m       \u001b[32m0.8173\u001b[0m        \u001b[35m0.4811\u001b[0m  45.7228\n",
      "      4        \u001b[36m0.4693\u001b[0m       \u001b[32m0.8391\u001b[0m        \u001b[35m0.4296\u001b[0m  45.5899\n",
      "      5        \u001b[36m0.4373\u001b[0m       \u001b[32m0.8459\u001b[0m        \u001b[35m0.4189\u001b[0m  45.4504\n",
      "      6        \u001b[36m0.4096\u001b[0m       \u001b[32m0.8499\u001b[0m        \u001b[35m0.4061\u001b[0m  44.4658\n",
      "      7        \u001b[36m0.3986\u001b[0m       \u001b[32m0.8600\u001b[0m        \u001b[35m0.3764\u001b[0m  45.5138\n",
      "      8        \u001b[36m0.3826\u001b[0m       0.8541        0.3864  44.3386\n",
      "  epoch    train_loss    valid_acc    valid_loss      dur\n",
      "-------  ------------  -----------  ------------  -------\n",
      "      1        \u001b[36m0.8100\u001b[0m       \u001b[32m0.7612\u001b[0m        \u001b[35m0.6180\u001b[0m  41.3747\n",
      "      2        \u001b[36m0.5779\u001b[0m       \u001b[32m0.8034\u001b[0m        \u001b[35m0.5245\u001b[0m  42.5981\n",
      "      3        \u001b[36m0.5136\u001b[0m       \u001b[32m0.8240\u001b[0m        \u001b[35m0.4614\u001b[0m  43.1661\n",
      "      4        \u001b[36m0.4716\u001b[0m       0.8221        \u001b[35m0.4591\u001b[0m  91.2434\n",
      "      5        \u001b[36m0.4493\u001b[0m       \u001b[32m0.8400\u001b[0m        \u001b[35m0.4223\u001b[0m  105.5063\n",
      "      6        \u001b[36m0.4268\u001b[0m       \u001b[32m0.8464\u001b[0m        0.4257  116.4499\n",
      "      7        \u001b[36m0.4114\u001b[0m       \u001b[32m0.8562\u001b[0m        \u001b[35m0.3870\u001b[0m  103.2614\n",
      "      8        \u001b[36m0.3997\u001b[0m       \u001b[32m0.8610\u001b[0m        \u001b[35m0.3848\u001b[0m  72.4562\n",
      "  epoch    train_loss    valid_acc    valid_loss      dur\n",
      "-------  ------------  -----------  ------------  -------\n",
      "      1        \u001b[36m0.7996\u001b[0m       \u001b[32m0.7592\u001b[0m        \u001b[35m0.6340\u001b[0m  22.8299\n",
      "      2        \u001b[36m0.5798\u001b[0m       \u001b[32m0.8105\u001b[0m        \u001b[35m0.5013\u001b[0m  23.0524\n",
      "      3        \u001b[36m0.5093\u001b[0m       \u001b[32m0.8317\u001b[0m        \u001b[35m0.4475\u001b[0m  23.8718\n",
      "      4        \u001b[36m0.4678\u001b[0m       \u001b[32m0.8426\u001b[0m        \u001b[35m0.4257\u001b[0m  48.9237\n",
      "      5        \u001b[36m0.4385\u001b[0m       \u001b[32m0.8480\u001b[0m        \u001b[35m0.4158\u001b[0m  58.0913\n",
      "      6        \u001b[36m0.4207\u001b[0m       \u001b[32m0.8608\u001b[0m        \u001b[35m0.3893\u001b[0m  116.6681\n",
      "      7        \u001b[36m0.4102\u001b[0m       0.8380        0.4193  79.8967\n",
      "      8        \u001b[36m0.4011\u001b[0m       \u001b[32m0.8611\u001b[0m        \u001b[35m0.3781\u001b[0m  74.4382\n",
      "  epoch    train_loss    valid_acc    valid_loss      dur\n",
      "-------  ------------  -----------  ------------  -------\n",
      "      1        \u001b[36m0.8141\u001b[0m       \u001b[32m0.7636\u001b[0m        \u001b[35m0.6210\u001b[0m  22.8433\n",
      "      2        \u001b[36m0.5840\u001b[0m       \u001b[32m0.7990\u001b[0m        \u001b[35m0.5219\u001b[0m  23.2368\n",
      "      3        \u001b[36m0.5167\u001b[0m       \u001b[32m0.8210\u001b[0m        \u001b[35m0.4814\u001b[0m  25.5703\n",
      "      4        \u001b[36m0.4719\u001b[0m       \u001b[32m0.8350\u001b[0m        \u001b[35m0.4480\u001b[0m  126.8133\n",
      "      5        \u001b[36m0.4448\u001b[0m       \u001b[32m0.8489\u001b[0m        \u001b[35m0.4069\u001b[0m  172.1445\n",
      "      6        \u001b[36m0.4274\u001b[0m       0.8439        0.4248  185.2747\n",
      "      7        \u001b[36m0.4136\u001b[0m       \u001b[32m0.8588\u001b[0m        \u001b[35m0.3799\u001b[0m  217.4075\n",
      "      8        \u001b[36m0.3941\u001b[0m       0.8380        0.4183  227.7106\n",
      "  epoch    train_loss    valid_acc    valid_loss      dur\n",
      "-------  ------------  -----------  ------------  -------\n",
      "      1        \u001b[36m2.2828\u001b[0m       \u001b[32m0.3267\u001b[0m        \u001b[35m2.2557\u001b[0m  39.5360\n",
      "      2        \u001b[36m2.2227\u001b[0m       \u001b[32m0.3564\u001b[0m        \u001b[35m2.1690\u001b[0m  39.3927\n",
      "      3        \u001b[36m2.0895\u001b[0m       \u001b[32m0.3985\u001b[0m        \u001b[35m1.9715\u001b[0m  39.1229\n",
      "      4        \u001b[36m1.8345\u001b[0m       \u001b[32m0.4708\u001b[0m        \u001b[35m1.6828\u001b[0m  39.2261\n",
      "      5        \u001b[36m1.5760\u001b[0m       \u001b[32m0.5054\u001b[0m        \u001b[35m1.4761\u001b[0m  39.4140\n",
      "      6        \u001b[36m1.4091\u001b[0m       \u001b[32m0.5291\u001b[0m        \u001b[35m1.3387\u001b[0m  39.2277\n",
      "      7        \u001b[36m1.3038\u001b[0m       \u001b[32m0.5535\u001b[0m        \u001b[35m1.2491\u001b[0m  38.8845\n",
      "      8        \u001b[36m1.2307\u001b[0m       \u001b[32m0.5789\u001b[0m        \u001b[35m1.1762\u001b[0m  39.2407\n",
      "  epoch    train_loss    valid_acc    valid_loss      dur\n",
      "-------  ------------  -----------  ------------  -------\n",
      "      1        \u001b[36m2.2872\u001b[0m       \u001b[32m0.3292\u001b[0m        \u001b[35m2.2609\u001b[0m  39.3668\n",
      "      2        \u001b[36m2.2325\u001b[0m       \u001b[32m0.4143\u001b[0m        \u001b[35m2.1840\u001b[0m  39.1219\n",
      "      3        \u001b[36m2.1234\u001b[0m       \u001b[32m0.4456\u001b[0m        \u001b[35m2.0227\u001b[0m  39.1961\n",
      "      4        \u001b[36m1.9110\u001b[0m       \u001b[32m0.4731\u001b[0m        \u001b[35m1.7540\u001b[0m  39.1287\n",
      "      5        \u001b[36m1.6471\u001b[0m       \u001b[32m0.5078\u001b[0m        \u001b[35m1.5118\u001b[0m  39.0943\n",
      "      6        \u001b[36m1.4565\u001b[0m       \u001b[32m0.5343\u001b[0m        \u001b[35m1.3584\u001b[0m  38.9841\n",
      "      7        \u001b[36m1.3320\u001b[0m       \u001b[32m0.5649\u001b[0m        \u001b[35m1.2419\u001b[0m  39.0573\n",
      "      8        \u001b[36m1.2517\u001b[0m       \u001b[32m0.5885\u001b[0m        \u001b[35m1.1755\u001b[0m  39.7440\n",
      "  epoch    train_loss    valid_acc    valid_loss      dur\n",
      "-------  ------------  -----------  ------------  -------\n",
      "      1        \u001b[36m2.2850\u001b[0m       \u001b[32m0.3236\u001b[0m        \u001b[35m2.2593\u001b[0m  39.4682\n",
      "      2        \u001b[36m2.2320\u001b[0m       \u001b[32m0.3952\u001b[0m        \u001b[35m2.1815\u001b[0m  39.1897\n",
      "      3        \u001b[36m2.1170\u001b[0m       \u001b[32m0.4286\u001b[0m        \u001b[35m2.0070\u001b[0m  39.2089\n",
      "      4        \u001b[36m1.8877\u001b[0m       \u001b[32m0.4642\u001b[0m        \u001b[35m1.7261\u001b[0m  39.1806\n",
      "      5        \u001b[36m1.6254\u001b[0m       \u001b[32m0.4938\u001b[0m        \u001b[35m1.4944\u001b[0m  39.4983\n",
      "      6        \u001b[36m1.4371\u001b[0m       \u001b[32m0.5405\u001b[0m        \u001b[35m1.3405\u001b[0m  39.2238\n",
      "      7        \u001b[36m1.3147\u001b[0m       \u001b[32m0.5677\u001b[0m        \u001b[35m1.2240\u001b[0m  39.2187\n",
      "      8        \u001b[36m1.2317\u001b[0m       \u001b[32m0.5889\u001b[0m        \u001b[35m1.1672\u001b[0m  39.4077\n",
      "  epoch    train_loss    valid_acc    valid_loss      dur\n",
      "-------  ------------  -----------  ------------  -------\n",
      "      1        \u001b[36m2.2640\u001b[0m       \u001b[32m0.3294\u001b[0m        \u001b[35m2.2182\u001b[0m  39.7263\n",
      "      2        \u001b[36m2.1607\u001b[0m       \u001b[32m0.4073\u001b[0m        \u001b[35m2.0698\u001b[0m  39.3006\n",
      "      3        \u001b[36m1.9452\u001b[0m       \u001b[32m0.4656\u001b[0m        \u001b[35m1.7881\u001b[0m  39.2260\n",
      "      4        \u001b[36m1.6530\u001b[0m       \u001b[32m0.5119\u001b[0m        \u001b[35m1.5229\u001b[0m  39.3566\n",
      "      5        \u001b[36m1.4458\u001b[0m       \u001b[32m0.5232\u001b[0m        \u001b[35m1.3845\u001b[0m  39.4203\n",
      "      6        \u001b[36m1.3294\u001b[0m       \u001b[32m0.5473\u001b[0m        \u001b[35m1.2829\u001b[0m  39.4099\n",
      "      7        \u001b[36m1.2429\u001b[0m       \u001b[32m0.5757\u001b[0m        \u001b[35m1.1949\u001b[0m  36.4507\n",
      "      8        \u001b[36m1.1874\u001b[0m       \u001b[32m0.5900\u001b[0m        \u001b[35m1.1434\u001b[0m  20.0038\n",
      "  epoch    train_loss    valid_acc    valid_loss      dur\n",
      "-------  ------------  -----------  ------------  -------\n",
      "      1        \u001b[36m2.2838\u001b[0m       \u001b[32m0.2671\u001b[0m        \u001b[35m2.2526\u001b[0m  17.5713\n",
      "      2        \u001b[36m2.2177\u001b[0m       \u001b[32m0.3889\u001b[0m        \u001b[35m2.1567\u001b[0m  18.7821\n",
      "      3        \u001b[36m2.0761\u001b[0m       \u001b[32m0.4412\u001b[0m        \u001b[35m1.9443\u001b[0m  19.2873\n",
      "      4        \u001b[36m1.8207\u001b[0m       \u001b[32m0.4709\u001b[0m        \u001b[35m1.6577\u001b[0m  18.9497\n",
      "      5        \u001b[36m1.5613\u001b[0m       \u001b[32m0.5134\u001b[0m        \u001b[35m1.4442\u001b[0m  19.2438\n",
      "      6        \u001b[36m1.3816\u001b[0m       \u001b[32m0.5565\u001b[0m        \u001b[35m1.2893\u001b[0m  19.3668\n",
      "      7        \u001b[36m1.2697\u001b[0m       \u001b[32m0.5769\u001b[0m        \u001b[35m1.2055\u001b[0m  19.1139\n",
      "      8        \u001b[36m1.1961\u001b[0m       \u001b[32m0.5929\u001b[0m        \u001b[35m1.1408\u001b[0m  19.4560\n",
      "  epoch    train_loss    valid_acc    valid_loss      dur\n",
      "-------  ------------  -----------  ------------  -------\n",
      "      1        \u001b[36m2.2824\u001b[0m       \u001b[32m0.3553\u001b[0m        \u001b[35m2.2561\u001b[0m  17.6292\n",
      "      2        \u001b[36m2.2276\u001b[0m       \u001b[32m0.3915\u001b[0m        \u001b[35m2.1755\u001b[0m  19.0100\n",
      "      3        \u001b[36m2.1072\u001b[0m       \u001b[32m0.4180\u001b[0m        \u001b[35m1.9927\u001b[0m  19.4761\n",
      "      4        \u001b[36m1.8704\u001b[0m       \u001b[32m0.4647\u001b[0m        \u001b[35m1.7111\u001b[0m  18.6504\n",
      "      5        \u001b[36m1.6103\u001b[0m       \u001b[32m0.5030\u001b[0m        \u001b[35m1.4770\u001b[0m  19.2990\n",
      "      6        \u001b[36m1.4287\u001b[0m       \u001b[32m0.5443\u001b[0m        \u001b[35m1.3283\u001b[0m  19.4073\n",
      "      7        \u001b[36m1.3025\u001b[0m       \u001b[32m0.5725\u001b[0m        \u001b[35m1.2249\u001b[0m  19.1735\n",
      "      8        \u001b[36m1.2217\u001b[0m       \u001b[32m0.5851\u001b[0m        \u001b[35m1.1548\u001b[0m  19.3426\n",
      "  epoch    train_loss    valid_acc    valid_loss      dur\n",
      "-------  ------------  -----------  ------------  -------\n",
      "      1        \u001b[36m0.8218\u001b[0m       \u001b[32m0.7514\u001b[0m        \u001b[35m0.6274\u001b[0m  20.1247\n",
      "      2        \u001b[36m0.5963\u001b[0m       \u001b[32m0.7863\u001b[0m        \u001b[35m0.5526\u001b[0m  21.5787\n",
      "      3        \u001b[36m0.5287\u001b[0m       \u001b[32m0.8111\u001b[0m        \u001b[35m0.4896\u001b[0m  21.4591\n",
      "      4        \u001b[36m0.4833\u001b[0m       \u001b[32m0.8375\u001b[0m        \u001b[35m0.4400\u001b[0m  22.2539\n",
      "      5        \u001b[36m0.4561\u001b[0m       \u001b[32m0.8425\u001b[0m        \u001b[35m0.4231\u001b[0m  21.6254\n",
      "      6        \u001b[36m0.4365\u001b[0m       \u001b[32m0.8534\u001b[0m        \u001b[35m0.3989\u001b[0m  21.9184\n",
      "      7        \u001b[36m0.4160\u001b[0m       \u001b[32m0.8618\u001b[0m        \u001b[35m0.3711\u001b[0m  21.8555\n",
      "      8        \u001b[36m0.4074\u001b[0m       0.8612        0.3796  21.4132\n",
      "  epoch    train_loss    valid_acc    valid_loss      dur\n",
      "-------  ------------  -----------  ------------  -------\n",
      "      1        \u001b[36m0.8248\u001b[0m       \u001b[32m0.7634\u001b[0m        \u001b[35m0.6332\u001b[0m  20.3192\n",
      "      2        \u001b[36m0.5924\u001b[0m       \u001b[32m0.7995\u001b[0m        \u001b[35m0.5247\u001b[0m  21.7381\n",
      "      3        \u001b[36m0.5238\u001b[0m       \u001b[32m0.8249\u001b[0m        \u001b[35m0.4618\u001b[0m  21.5553\n",
      "      4        \u001b[36m0.4851\u001b[0m       \u001b[32m0.8363\u001b[0m        \u001b[35m0.4456\u001b[0m  21.7462\n",
      "      5        \u001b[36m0.4605\u001b[0m       \u001b[32m0.8552\u001b[0m        \u001b[35m0.3967\u001b[0m  21.9031\n",
      "      6        \u001b[36m0.4369\u001b[0m       0.8551        \u001b[35m0.3898\u001b[0m  21.0519\n",
      "      7        \u001b[36m0.4206\u001b[0m       \u001b[32m0.8605\u001b[0m        \u001b[35m0.3800\u001b[0m  22.1146\n",
      "      8        \u001b[36m0.4050\u001b[0m       0.8538        0.3909  22.8961\n",
      "  epoch    train_loss    valid_acc    valid_loss      dur\n",
      "-------  ------------  -----------  ------------  -------\n",
      "      1        \u001b[36m0.8350\u001b[0m       \u001b[32m0.7631\u001b[0m        \u001b[35m0.6390\u001b[0m  22.2218\n",
      "      2        \u001b[36m0.5953\u001b[0m       \u001b[32m0.7994\u001b[0m        \u001b[35m0.5282\u001b[0m  23.8886\n",
      "      3        \u001b[36m0.5312\u001b[0m       \u001b[32m0.8267\u001b[0m        \u001b[35m0.4684\u001b[0m  24.7833\n",
      "      4        \u001b[36m0.4868\u001b[0m       \u001b[32m0.8409\u001b[0m        \u001b[35m0.4214\u001b[0m  24.5158\n",
      "      5        \u001b[36m0.4618\u001b[0m       \u001b[32m0.8446\u001b[0m        \u001b[35m0.4209\u001b[0m  23.5554\n",
      "      6        \u001b[36m0.4362\u001b[0m       \u001b[32m0.8575\u001b[0m        \u001b[35m0.3896\u001b[0m  24.2822\n",
      "      7        \u001b[36m0.4191\u001b[0m       0.8568        \u001b[35m0.3742\u001b[0m  23.8115\n",
      "      8        \u001b[36m0.4057\u001b[0m       \u001b[32m0.8678\u001b[0m        \u001b[35m0.3713\u001b[0m  24.3726\n",
      "  epoch    train_loss    valid_acc    valid_loss      dur\n",
      "-------  ------------  -----------  ------------  -------\n",
      "      1        \u001b[36m0.8331\u001b[0m       \u001b[32m0.7668\u001b[0m        \u001b[35m0.6150\u001b[0m  22.5454\n",
      "      2        \u001b[36m0.6112\u001b[0m       \u001b[32m0.7961\u001b[0m        \u001b[35m0.5306\u001b[0m  23.1646\n",
      "      3        \u001b[36m0.5417\u001b[0m       \u001b[32m0.8231\u001b[0m        \u001b[35m0.4738\u001b[0m  24.7409\n",
      "      4        \u001b[36m0.5013\u001b[0m       \u001b[32m0.8267\u001b[0m        \u001b[35m0.4614\u001b[0m  48.6539\n",
      "      5        \u001b[36m0.4730\u001b[0m       \u001b[32m0.8415\u001b[0m        \u001b[35m0.4279\u001b[0m  57.1466\n",
      "      6        \u001b[36m0.4545\u001b[0m       0.8357        0.4361  64.0497\n",
      "      7        \u001b[36m0.4346\u001b[0m       \u001b[32m0.8510\u001b[0m        \u001b[35m0.3961\u001b[0m  70.8920\n",
      "      8        \u001b[36m0.4266\u001b[0m       \u001b[32m0.8548\u001b[0m        \u001b[35m0.3928\u001b[0m  81.1761\n",
      "  epoch    train_loss    valid_acc    valid_loss      dur\n",
      "-------  ------------  -----------  ------------  -------\n",
      "      1        \u001b[36m0.8178\u001b[0m       \u001b[32m0.7589\u001b[0m        \u001b[35m0.6213\u001b[0m  22.9491\n",
      "      2        \u001b[36m0.5973\u001b[0m       \u001b[32m0.7904\u001b[0m        \u001b[35m0.5307\u001b[0m  25.0418\n",
      "      3        \u001b[36m0.5327\u001b[0m       \u001b[32m0.8315\u001b[0m        \u001b[35m0.4694\u001b[0m  44.3015\n",
      "      4        \u001b[36m0.4870\u001b[0m       \u001b[32m0.8414\u001b[0m        \u001b[35m0.4287\u001b[0m  80.3382\n",
      "      5        \u001b[36m0.4616\u001b[0m       0.8374        \u001b[35m0.4258\u001b[0m  97.9102\n",
      "      6        \u001b[36m0.4433\u001b[0m       0.8271        0.4456  110.9329\n",
      "      7        \u001b[36m0.4298\u001b[0m       \u001b[32m0.8626\u001b[0m        \u001b[35m0.3792\u001b[0m  62.3821\n",
      "      8        \u001b[36m0.4233\u001b[0m       0.8582        \u001b[35m0.3789\u001b[0m  67.6225\n",
      "  epoch    train_loss    valid_acc    valid_loss      dur\n",
      "-------  ------------  -----------  ------------  -------\n",
      "      1        \u001b[36m0.8240\u001b[0m       \u001b[32m0.7672\u001b[0m        \u001b[35m0.6049\u001b[0m  22.4970\n",
      "      2        \u001b[36m0.6025\u001b[0m       \u001b[32m0.7959\u001b[0m        \u001b[35m0.5355\u001b[0m  22.8885\n",
      "      3        \u001b[36m0.5396\u001b[0m       \u001b[32m0.8240\u001b[0m        \u001b[35m0.4671\u001b[0m  24.0498\n",
      "      4        \u001b[36m0.5002\u001b[0m       \u001b[32m0.8273\u001b[0m        \u001b[35m0.4563\u001b[0m  47.3985\n",
      "      5        \u001b[36m0.4685\u001b[0m       \u001b[32m0.8410\u001b[0m        \u001b[35m0.4259\u001b[0m  50.3811\n",
      "      6        \u001b[36m0.4503\u001b[0m       \u001b[32m0.8574\u001b[0m        \u001b[35m0.4021\u001b[0m  48.9475\n",
      "      7        \u001b[36m0.4380\u001b[0m       0.8550        \u001b[35m0.3871\u001b[0m  51.4160\n",
      "      8        \u001b[36m0.4229\u001b[0m       \u001b[32m0.8610\u001b[0m        \u001b[35m0.3829\u001b[0m  56.7231\n",
      "  epoch    train_loss    valid_acc    valid_loss      dur\n",
      "-------  ------------  -----------  ------------  -------\n",
      "      1        \u001b[36m2.2795\u001b[0m       \u001b[32m0.2782\u001b[0m        \u001b[35m2.2463\u001b[0m  20.7088\n",
      "      2        \u001b[36m2.2126\u001b[0m       \u001b[32m0.3294\u001b[0m        \u001b[35m2.1433\u001b[0m  21.4658\n",
      "      3        \u001b[36m2.0619\u001b[0m       \u001b[32m0.4354\u001b[0m        \u001b[35m1.9222\u001b[0m  21.3437\n",
      "      4        \u001b[36m1.7975\u001b[0m       \u001b[32m0.4776\u001b[0m        \u001b[35m1.6375\u001b[0m  21.4133\n",
      "      5        \u001b[36m1.5647\u001b[0m       \u001b[32m0.5081\u001b[0m        \u001b[35m1.4581\u001b[0m  21.1972\n",
      "      6        \u001b[36m1.4315\u001b[0m       \u001b[32m0.5336\u001b[0m        \u001b[35m1.3423\u001b[0m  21.3991\n",
      "      7        \u001b[36m1.3506\u001b[0m       \u001b[32m0.5540\u001b[0m        \u001b[35m1.2578\u001b[0m  21.4211\n",
      "      8        \u001b[36m1.2772\u001b[0m       \u001b[32m0.5763\u001b[0m        \u001b[35m1.1997\u001b[0m  21.8445\n",
      "  epoch    train_loss    valid_acc    valid_loss      dur\n",
      "-------  ------------  -----------  ------------  -------\n",
      "      1        \u001b[36m2.2948\u001b[0m       \u001b[32m0.2406\u001b[0m        \u001b[35m2.2785\u001b[0m  20.4636\n",
      "      2        \u001b[36m2.2665\u001b[0m       \u001b[32m0.3314\u001b[0m        \u001b[35m2.2368\u001b[0m  21.6649\n",
      "      3        \u001b[36m2.2095\u001b[0m       \u001b[32m0.4118\u001b[0m        \u001b[35m2.1456\u001b[0m  21.2790\n",
      "      4        \u001b[36m2.0740\u001b[0m       \u001b[32m0.4409\u001b[0m        \u001b[35m1.9343\u001b[0m  21.4060\n",
      "      5        \u001b[36m1.8141\u001b[0m       \u001b[32m0.4891\u001b[0m        \u001b[35m1.6286\u001b[0m  21.5924\n",
      "      6        \u001b[36m1.5594\u001b[0m       \u001b[32m0.5229\u001b[0m        \u001b[35m1.4232\u001b[0m  21.5926\n",
      "      7        \u001b[36m1.4004\u001b[0m       \u001b[32m0.5411\u001b[0m        \u001b[35m1.3034\u001b[0m  21.4282\n",
      "      8        \u001b[36m1.3113\u001b[0m       \u001b[32m0.5731\u001b[0m        \u001b[35m1.2192\u001b[0m  21.4183\n",
      "  epoch    train_loss    valid_acc    valid_loss      dur\n",
      "-------  ------------  -----------  ------------  -------\n",
      "      1        \u001b[36m2.2834\u001b[0m       \u001b[32m0.3056\u001b[0m        \u001b[35m2.2495\u001b[0m  20.7077\n",
      "      2        \u001b[36m2.2188\u001b[0m       \u001b[32m0.3787\u001b[0m        \u001b[35m2.1488\u001b[0m  21.3140\n",
      "      3        \u001b[36m2.0712\u001b[0m       \u001b[32m0.4384\u001b[0m        \u001b[35m1.9192\u001b[0m  21.2695\n",
      "      4        \u001b[36m1.8006\u001b[0m       \u001b[32m0.5016\u001b[0m        \u001b[35m1.6104\u001b[0m  22.6016\n",
      "      5        \u001b[36m1.5499\u001b[0m       \u001b[32m0.5373\u001b[0m        \u001b[35m1.4078\u001b[0m  21.6157\n",
      "      6        \u001b[36m1.4193\u001b[0m       \u001b[32m0.5496\u001b[0m        \u001b[35m1.2913\u001b[0m  21.8065\n",
      "      7        \u001b[36m1.3300\u001b[0m       \u001b[32m0.5699\u001b[0m        \u001b[35m1.2169\u001b[0m  21.6376\n",
      "      8        \u001b[36m1.2572\u001b[0m       \u001b[32m0.6001\u001b[0m        \u001b[35m1.1525\u001b[0m  21.6738\n",
      "  epoch    train_loss    valid_acc    valid_loss      dur\n",
      "-------  ------------  -----------  ------------  -------\n",
      "      1        \u001b[36m2.2813\u001b[0m       \u001b[32m0.2709\u001b[0m        \u001b[35m2.2428\u001b[0m  20.2317\n",
      "      2        \u001b[36m2.1999\u001b[0m       \u001b[32m0.3658\u001b[0m        \u001b[35m2.1105\u001b[0m  20.4636\n",
      "      3        \u001b[36m2.0025\u001b[0m       \u001b[32m0.4455\u001b[0m        \u001b[35m1.8261\u001b[0m  21.3764\n",
      "      4        \u001b[36m1.6921\u001b[0m       \u001b[32m0.5102\u001b[0m        \u001b[35m1.5252\u001b[0m  20.9503\n",
      "      5        \u001b[36m1.4864\u001b[0m       \u001b[32m0.5191\u001b[0m        \u001b[35m1.3819\u001b[0m  21.8063\n",
      "      6        \u001b[36m1.3719\u001b[0m       \u001b[32m0.5563\u001b[0m        \u001b[35m1.2712\u001b[0m  21.4393\n",
      "      7        \u001b[36m1.2990\u001b[0m       \u001b[32m0.5645\u001b[0m        \u001b[35m1.2139\u001b[0m  21.8650\n",
      "      8        \u001b[36m1.2489\u001b[0m       \u001b[32m0.5876\u001b[0m        \u001b[35m1.1670\u001b[0m  21.6765\n",
      "  epoch    train_loss    valid_acc    valid_loss      dur\n",
      "-------  ------------  -----------  ------------  -------\n",
      "      1        \u001b[36m2.2890\u001b[0m       \u001b[32m0.2736\u001b[0m        \u001b[35m2.2647\u001b[0m  20.3244\n",
      "      2        \u001b[36m2.2426\u001b[0m       \u001b[32m0.3526\u001b[0m        \u001b[35m2.1946\u001b[0m  21.6233\n",
      "      3        \u001b[36m2.1426\u001b[0m       \u001b[32m0.3931\u001b[0m        \u001b[35m2.0384\u001b[0m  21.4937\n",
      "      4        \u001b[36m1.9352\u001b[0m       \u001b[32m0.4386\u001b[0m        \u001b[35m1.7666\u001b[0m  21.3484\n",
      "      5        \u001b[36m1.6761\u001b[0m       \u001b[32m0.4904\u001b[0m        \u001b[35m1.5323\u001b[0m  21.3645\n",
      "      6        \u001b[36m1.4821\u001b[0m       \u001b[32m0.5136\u001b[0m        \u001b[35m1.3691\u001b[0m  20.8225\n",
      "      7        \u001b[36m1.3557\u001b[0m       \u001b[32m0.5454\u001b[0m        \u001b[35m1.2759\u001b[0m  21.0838\n",
      "      8        \u001b[36m1.2744\u001b[0m       \u001b[32m0.5725\u001b[0m        \u001b[35m1.1970\u001b[0m  20.9937\n",
      "  epoch    train_loss    valid_acc    valid_loss      dur\n",
      "-------  ------------  -----------  ------------  -------\n",
      "      1        \u001b[36m2.2872\u001b[0m       \u001b[32m0.2946\u001b[0m        \u001b[35m2.2595\u001b[0m  20.8010\n",
      "      2        \u001b[36m2.2332\u001b[0m       \u001b[32m0.3971\u001b[0m        \u001b[35m2.1752\u001b[0m  21.5596\n",
      "      3        \u001b[36m2.1133\u001b[0m       \u001b[32m0.4665\u001b[0m        \u001b[35m1.9858\u001b[0m  21.5024\n",
      "      4        \u001b[36m1.8732\u001b[0m       \u001b[32m0.4880\u001b[0m        \u001b[35m1.6991\u001b[0m  21.5927\n",
      "      5        \u001b[36m1.6137\u001b[0m       \u001b[32m0.5212\u001b[0m        \u001b[35m1.4708\u001b[0m  21.4894\n",
      "      6        \u001b[36m1.4459\u001b[0m       \u001b[32m0.5366\u001b[0m        \u001b[35m1.3366\u001b[0m  21.5533\n",
      "      7        \u001b[36m1.3387\u001b[0m       \u001b[32m0.5724\u001b[0m        \u001b[35m1.2412\u001b[0m  21.2351\n",
      "      8        \u001b[36m1.2619\u001b[0m       \u001b[32m0.5950\u001b[0m        \u001b[35m1.1710\u001b[0m  21.3475\n",
      "  epoch    train_loss    valid_acc    valid_loss      dur\n",
      "-------  ------------  -----------  ------------  -------\n",
      "      1        \u001b[36m0.8573\u001b[0m       \u001b[32m0.7502\u001b[0m        \u001b[35m0.6678\u001b[0m  22.8888\n",
      "      2        \u001b[36m0.6174\u001b[0m       \u001b[32m0.7785\u001b[0m        \u001b[35m0.5780\u001b[0m  23.3944\n",
      "      3        \u001b[36m0.5555\u001b[0m       \u001b[32m0.7973\u001b[0m        \u001b[35m0.5273\u001b[0m  23.6580\n",
      "      4        \u001b[36m0.5187\u001b[0m       \u001b[32m0.8240\u001b[0m        \u001b[35m0.4808\u001b[0m  23.5325\n",
      "      5        \u001b[36m0.4851\u001b[0m       0.8206        \u001b[35m0.4682\u001b[0m  23.4178\n",
      "  epoch    train_loss    valid_acc    valid_loss      dur\n",
      "-------  ------------  -----------  ------------  -------\n",
      "      1        \u001b[36m0.8662\u001b[0m       \u001b[32m0.7466\u001b[0m        \u001b[35m0.6681\u001b[0m  22.4957\n",
      "      2        \u001b[36m0.6259\u001b[0m       \u001b[32m0.7957\u001b[0m        \u001b[35m0.5392\u001b[0m  23.6797\n",
      "      3        \u001b[36m0.5480\u001b[0m       \u001b[32m0.8043\u001b[0m        \u001b[35m0.5083\u001b[0m  23.1786\n",
      "      4        \u001b[36m0.5080\u001b[0m       \u001b[32m0.8099\u001b[0m        \u001b[35m0.4862\u001b[0m  23.8960\n",
      "      5        \u001b[36m0.4742\u001b[0m       \u001b[32m0.8391\u001b[0m        \u001b[35m0.4346\u001b[0m  33.1209\n",
      "  epoch    train_loss    valid_acc    valid_loss      dur\n",
      "-------  ------------  -----------  ------------  -------\n",
      "      1        \u001b[36m0.8844\u001b[0m       \u001b[32m0.7484\u001b[0m        \u001b[35m0.6718\u001b[0m  26.4709\n",
      "      2        \u001b[36m0.6364\u001b[0m       \u001b[32m0.7760\u001b[0m        \u001b[35m0.5789\u001b[0m  23.9555\n",
      "      3        \u001b[36m0.5677\u001b[0m       \u001b[32m0.8105\u001b[0m        \u001b[35m0.5143\u001b[0m  23.9765\n",
      "      4        \u001b[36m0.5201\u001b[0m       0.8093        \u001b[35m0.5001\u001b[0m  24.2001\n",
      "      5        \u001b[36m0.4881\u001b[0m       \u001b[32m0.8134\u001b[0m        \u001b[35m0.4826\u001b[0m  23.5872\n",
      "  epoch    train_loss    valid_acc    valid_loss      dur\n",
      "-------  ------------  -----------  ------------  -------\n",
      "      1        \u001b[36m0.8978\u001b[0m       \u001b[32m0.7266\u001b[0m        \u001b[35m0.7083\u001b[0m  22.3007\n",
      "      2        \u001b[36m0.6391\u001b[0m       \u001b[32m0.7598\u001b[0m        \u001b[35m0.6190\u001b[0m  23.5789\n",
      "      3        \u001b[36m0.5710\u001b[0m       \u001b[32m0.7886\u001b[0m        \u001b[35m0.5395\u001b[0m  23.4133\n",
      "      4        \u001b[36m0.5268\u001b[0m       \u001b[32m0.8154\u001b[0m        \u001b[35m0.4891\u001b[0m  36.1594\n",
      "      5        \u001b[36m0.4911\u001b[0m       0.8145        \u001b[35m0.4812\u001b[0m  39.1530\n",
      "  epoch    train_loss    valid_acc    valid_loss      dur\n",
      "-------  ------------  -----------  ------------  -------\n",
      "      1        \u001b[36m0.8764\u001b[0m       \u001b[32m0.7488\u001b[0m        \u001b[35m0.6508\u001b[0m  22.5785\n",
      "      2        \u001b[36m0.6295\u001b[0m       \u001b[32m0.7884\u001b[0m        \u001b[35m0.5650\u001b[0m  22.8737\n",
      "      3        \u001b[36m0.5634\u001b[0m       \u001b[32m0.8006\u001b[0m        \u001b[35m0.5215\u001b[0m  23.4947\n",
      "      4        \u001b[36m0.5242\u001b[0m       \u001b[32m0.8295\u001b[0m        \u001b[35m0.4739\u001b[0m  36.8523\n",
      "      5        \u001b[36m0.4852\u001b[0m       0.8200        \u001b[35m0.4737\u001b[0m  41.9447\n",
      "  epoch    train_loss    valid_acc    valid_loss      dur\n",
      "-------  ------------  -----------  ------------  -------\n",
      "      1        \u001b[36m0.8618\u001b[0m       \u001b[32m0.7399\u001b[0m        \u001b[35m0.6673\u001b[0m  22.2091\n",
      "      2        \u001b[36m0.6227\u001b[0m       \u001b[32m0.7839\u001b[0m        \u001b[35m0.5727\u001b[0m  23.0529\n",
      "      3        \u001b[36m0.5456\u001b[0m       \u001b[32m0.8025\u001b[0m        \u001b[35m0.5134\u001b[0m  24.3123\n",
      "      4        \u001b[36m0.5116\u001b[0m       \u001b[32m0.8109\u001b[0m        \u001b[35m0.4985\u001b[0m  42.6509\n",
      "      5        \u001b[36m0.4794\u001b[0m       \u001b[32m0.8310\u001b[0m        \u001b[35m0.4556\u001b[0m  44.5040\n",
      "  epoch    train_loss    valid_acc    valid_loss      dur\n",
      "-------  ------------  -----------  ------------  -------\n",
      "      1        \u001b[36m2.2862\u001b[0m       \u001b[32m0.1436\u001b[0m        \u001b[35m2.2684\u001b[0m  20.0375\n",
      "      2        \u001b[36m2.2533\u001b[0m       \u001b[32m0.3169\u001b[0m        \u001b[35m2.2275\u001b[0m  21.0743\n",
      "      3        \u001b[36m2.2042\u001b[0m       \u001b[32m0.3521\u001b[0m        \u001b[35m2.1641\u001b[0m  20.8929\n",
      "      4        \u001b[36m2.1259\u001b[0m       \u001b[32m0.3816\u001b[0m        \u001b[35m2.0646\u001b[0m  20.9774\n",
      "      5        \u001b[36m2.0019\u001b[0m       \u001b[32m0.4390\u001b[0m        \u001b[35m1.9174\u001b[0m  21.1485\n",
      "  epoch    train_loss    valid_acc    valid_loss      dur\n",
      "-------  ------------  -----------  ------------  -------\n",
      "      1        \u001b[36m2.2935\u001b[0m       \u001b[32m0.1801\u001b[0m        \u001b[35m2.2830\u001b[0m  20.3139\n",
      "      2        \u001b[36m2.2751\u001b[0m       \u001b[32m0.2650\u001b[0m        \u001b[35m2.2613\u001b[0m  21.3944\n",
      "      3        \u001b[36m2.2521\u001b[0m       \u001b[32m0.3229\u001b[0m        \u001b[35m2.2316\u001b[0m  21.3533\n",
      "      4        \u001b[36m2.2194\u001b[0m       \u001b[32m0.3513\u001b[0m        \u001b[35m2.1907\u001b[0m  20.9963\n",
      "      5        \u001b[36m2.1688\u001b[0m       \u001b[32m0.3847\u001b[0m        \u001b[35m2.1277\u001b[0m  21.3456\n",
      "  epoch    train_loss    valid_acc    valid_loss      dur\n",
      "-------  ------------  -----------  ------------  -------\n",
      "      1        \u001b[36m2.2954\u001b[0m       \u001b[32m0.1756\u001b[0m        \u001b[35m2.2858\u001b[0m  20.1919\n",
      "      2        \u001b[36m2.2791\u001b[0m       \u001b[32m0.3435\u001b[0m        \u001b[35m2.2668\u001b[0m  21.1359\n",
      "      3        \u001b[36m2.2586\u001b[0m       \u001b[32m0.3937\u001b[0m        \u001b[35m2.2407\u001b[0m  21.3266\n",
      "      4        \u001b[36m2.2298\u001b[0m       0.3811        \u001b[35m2.2039\u001b[0m  21.4928\n",
      "      5        \u001b[36m2.1859\u001b[0m       0.3812        \u001b[35m2.1507\u001b[0m  21.3236\n",
      "  epoch    train_loss    valid_acc    valid_loss      dur\n",
      "-------  ------------  -----------  ------------  -------\n",
      "      1        \u001b[36m2.2934\u001b[0m       \u001b[32m0.2203\u001b[0m        \u001b[35m2.2818\u001b[0m  20.3218\n",
      "      2        \u001b[36m2.2732\u001b[0m       \u001b[32m0.2574\u001b[0m        \u001b[35m2.2576\u001b[0m  21.1336\n",
      "      3        \u001b[36m2.2457\u001b[0m       \u001b[32m0.2945\u001b[0m        \u001b[35m2.2243\u001b[0m  21.4442\n",
      "      4        \u001b[36m2.2060\u001b[0m       \u001b[32m0.3317\u001b[0m        \u001b[35m2.1740\u001b[0m  21.1766\n",
      "      5        \u001b[36m2.1439\u001b[0m       \u001b[32m0.3755\u001b[0m        \u001b[35m2.0956\u001b[0m  20.9381\n",
      "  epoch    train_loss    valid_acc    valid_loss      dur\n",
      "-------  ------------  -----------  ------------  -------\n",
      "      1        \u001b[36m2.2938\u001b[0m       \u001b[32m0.2316\u001b[0m        \u001b[35m2.2791\u001b[0m  20.2915\n",
      "      2        \u001b[36m2.2676\u001b[0m       \u001b[32m0.3749\u001b[0m        \u001b[35m2.2479\u001b[0m  21.1425\n",
      "      3        \u001b[36m2.2325\u001b[0m       \u001b[32m0.4130\u001b[0m        \u001b[35m2.2036\u001b[0m  21.5151\n",
      "      4        \u001b[36m2.1782\u001b[0m       \u001b[32m0.4224\u001b[0m        \u001b[35m2.1316\u001b[0m  21.5269\n",
      "      5        \u001b[36m2.0914\u001b[0m       \u001b[32m0.4369\u001b[0m        \u001b[35m2.0193\u001b[0m  21.1062\n",
      "  epoch    train_loss    valid_acc    valid_loss      dur\n",
      "-------  ------------  -----------  ------------  -------\n",
      "      1        \u001b[36m2.2962\u001b[0m       \u001b[32m0.1865\u001b[0m        \u001b[35m2.2849\u001b[0m  20.1411\n",
      "      2        \u001b[36m2.2767\u001b[0m       \u001b[32m0.2699\u001b[0m        \u001b[35m2.2625\u001b[0m  21.2053\n",
      "      3        \u001b[36m2.2530\u001b[0m       \u001b[32m0.3420\u001b[0m        \u001b[35m2.2347\u001b[0m  21.1962\n",
      "      4        \u001b[36m2.2216\u001b[0m       \u001b[32m0.3733\u001b[0m        \u001b[35m2.1934\u001b[0m  21.4224\n",
      "      5        \u001b[36m2.1743\u001b[0m       \u001b[32m0.3905\u001b[0m        \u001b[35m2.1336\u001b[0m  21.1694\n",
      "  epoch    train_loss    valid_acc    valid_loss      dur\n",
      "-------  ------------  -----------  ------------  -------\n",
      "      1        \u001b[36m0.9163\u001b[0m       \u001b[32m0.7262\u001b[0m        \u001b[35m0.6984\u001b[0m  22.7200\n",
      "      2        \u001b[36m0.6568\u001b[0m       \u001b[32m0.7730\u001b[0m        \u001b[35m0.6064\u001b[0m  23.7823\n",
      "      3        \u001b[36m0.5900\u001b[0m       \u001b[32m0.7971\u001b[0m        \u001b[35m0.5407\u001b[0m  23.7449\n",
      "      4        \u001b[36m0.5458\u001b[0m       \u001b[32m0.8069\u001b[0m        \u001b[35m0.5150\u001b[0m  24.1294\n",
      "      5        \u001b[36m0.5112\u001b[0m       \u001b[32m0.8190\u001b[0m        \u001b[35m0.4925\u001b[0m  23.6839\n",
      "  epoch    train_loss    valid_acc    valid_loss      dur\n",
      "-------  ------------  -----------  ------------  -------\n",
      "      1        \u001b[36m0.8768\u001b[0m       \u001b[32m0.7519\u001b[0m        \u001b[35m0.6444\u001b[0m  22.4210\n",
      "      2        \u001b[36m0.6439\u001b[0m       \u001b[32m0.7824\u001b[0m        \u001b[35m0.5762\u001b[0m  23.2728\n",
      "      3        \u001b[36m0.5693\u001b[0m       \u001b[32m0.8059\u001b[0m        \u001b[35m0.5015\u001b[0m  23.1139\n",
      "      4        \u001b[36m0.5286\u001b[0m       \u001b[32m0.8186\u001b[0m        \u001b[35m0.4752\u001b[0m  23.7364\n",
      "      5        \u001b[36m0.4926\u001b[0m       \u001b[32m0.8291\u001b[0m        \u001b[35m0.4588\u001b[0m  23.6593\n",
      "  epoch    train_loss    valid_acc    valid_loss      dur\n",
      "-------  ------------  -----------  ------------  -------\n",
      "      1        \u001b[36m0.8937\u001b[0m       \u001b[32m0.7571\u001b[0m        \u001b[35m0.6637\u001b[0m  22.7543\n",
      "      2        \u001b[36m0.6403\u001b[0m       \u001b[32m0.7877\u001b[0m        \u001b[35m0.5641\u001b[0m  23.1141\n",
      "      3        \u001b[36m0.5762\u001b[0m       \u001b[32m0.8065\u001b[0m        \u001b[35m0.5198\u001b[0m  23.0768\n",
      "      4        \u001b[36m0.5334\u001b[0m       \u001b[32m0.8170\u001b[0m        \u001b[35m0.4860\u001b[0m  23.2644\n",
      "      5        \u001b[36m0.4973\u001b[0m       \u001b[32m0.8325\u001b[0m        \u001b[35m0.4435\u001b[0m  23.6833\n",
      "  epoch    train_loss    valid_acc    valid_loss      dur\n",
      "-------  ------------  -----------  ------------  -------\n",
      "      1        \u001b[36m0.8976\u001b[0m       \u001b[32m0.7301\u001b[0m        \u001b[35m0.6794\u001b[0m  22.6737\n",
      "      2        \u001b[36m0.6517\u001b[0m       \u001b[32m0.7720\u001b[0m        \u001b[35m0.6028\u001b[0m  22.8817\n",
      "      3        \u001b[36m0.5837\u001b[0m       \u001b[32m0.7929\u001b[0m        \u001b[35m0.5434\u001b[0m  23.1145\n",
      "      4        \u001b[36m0.5405\u001b[0m       \u001b[32m0.8149\u001b[0m        \u001b[35m0.4882\u001b[0m  29.6427\n",
      "      5        \u001b[36m0.5116\u001b[0m       \u001b[32m0.8255\u001b[0m        \u001b[35m0.4680\u001b[0m  31.4699\n",
      "  epoch    train_loss    valid_acc    valid_loss      dur\n",
      "-------  ------------  -----------  ------------  -------\n",
      "      1        \u001b[36m0.8780\u001b[0m       \u001b[32m0.7579\u001b[0m        \u001b[35m0.6562\u001b[0m  22.6846\n",
      "      2        \u001b[36m0.6482\u001b[0m       \u001b[32m0.7785\u001b[0m        \u001b[35m0.5756\u001b[0m  22.9697\n",
      "      3        \u001b[36m0.5852\u001b[0m       \u001b[32m0.8033\u001b[0m        \u001b[35m0.5275\u001b[0m  23.0885\n",
      "      4        \u001b[36m0.5413\u001b[0m       \u001b[32m0.8197\u001b[0m        \u001b[35m0.4814\u001b[0m  31.7122\n",
      "      5        \u001b[36m0.5082\u001b[0m       \u001b[32m0.8274\u001b[0m        \u001b[35m0.4597\u001b[0m  33.2933\n",
      "  epoch    train_loss    valid_acc    valid_loss      dur\n",
      "-------  ------------  -----------  ------------  -------\n",
      "      1        \u001b[36m0.8870\u001b[0m       \u001b[32m0.7518\u001b[0m        \u001b[35m0.6507\u001b[0m  22.7116\n",
      "      2        \u001b[36m0.6447\u001b[0m       \u001b[32m0.7756\u001b[0m        \u001b[35m0.5814\u001b[0m  22.4360\n",
      "      3        \u001b[36m0.5761\u001b[0m       \u001b[32m0.7903\u001b[0m        \u001b[35m0.5406\u001b[0m  23.2335\n",
      "      4        \u001b[36m0.5372\u001b[0m       \u001b[32m0.8045\u001b[0m        \u001b[35m0.5155\u001b[0m  31.6694\n",
      "      5        \u001b[36m0.5040\u001b[0m       \u001b[32m0.8333\u001b[0m        \u001b[35m0.4428\u001b[0m  35.9735\n",
      "  epoch    train_loss    valid_acc    valid_loss      dur\n",
      "-------  ------------  -----------  ------------  -------\n",
      "      1        \u001b[36m2.2976\u001b[0m       \u001b[32m0.1619\u001b[0m        \u001b[35m2.2852\u001b[0m  20.3299\n",
      "      2        \u001b[36m2.2778\u001b[0m       \u001b[32m0.3315\u001b[0m        \u001b[35m2.2616\u001b[0m  21.5422\n",
      "      3        \u001b[36m2.2547\u001b[0m       \u001b[32m0.3799\u001b[0m        \u001b[35m2.2312\u001b[0m  21.1523\n",
      "      4        \u001b[36m2.2220\u001b[0m       \u001b[32m0.4094\u001b[0m        \u001b[35m2.1898\u001b[0m  21.8966\n",
      "      5        \u001b[36m2.1734\u001b[0m       \u001b[32m0.4185\u001b[0m        \u001b[35m2.1260\u001b[0m  21.4016\n",
      "  epoch    train_loss    valid_acc    valid_loss      dur\n",
      "-------  ------------  -----------  ------------  -------\n",
      "      1        \u001b[36m2.2951\u001b[0m       \u001b[32m0.1886\u001b[0m        \u001b[35m2.2802\u001b[0m  20.1568\n",
      "      2        \u001b[36m2.2723\u001b[0m       \u001b[32m0.2984\u001b[0m        \u001b[35m2.2528\u001b[0m  21.4311\n",
      "      3        \u001b[36m2.2457\u001b[0m       \u001b[32m0.3286\u001b[0m        \u001b[35m2.2186\u001b[0m  21.6301\n",
      "      4        \u001b[36m2.2072\u001b[0m       \u001b[32m0.3641\u001b[0m        \u001b[35m2.1683\u001b[0m  21.2718\n",
      "      5        \u001b[36m2.1493\u001b[0m       \u001b[32m0.4064\u001b[0m        \u001b[35m2.0901\u001b[0m  21.4881\n",
      "  epoch    train_loss    valid_acc    valid_loss      dur\n",
      "-------  ------------  -----------  ------------  -------\n",
      "      1        \u001b[36m2.2970\u001b[0m       \u001b[32m0.2224\u001b[0m        \u001b[35m2.2856\u001b[0m  20.2112\n",
      "      2        \u001b[36m2.2809\u001b[0m       \u001b[32m0.2976\u001b[0m        \u001b[35m2.2657\u001b[0m  21.3920\n",
      "      3        \u001b[36m2.2615\u001b[0m       \u001b[32m0.3739\u001b[0m        \u001b[35m2.2407\u001b[0m  21.4169\n",
      "      4        \u001b[36m2.2351\u001b[0m       \u001b[32m0.3979\u001b[0m        \u001b[35m2.2059\u001b[0m  36.9096\n",
      "      5        \u001b[36m2.1968\u001b[0m       \u001b[32m0.4139\u001b[0m        \u001b[35m2.1557\u001b[0m  39.0981\n",
      "  epoch    train_loss    valid_acc    valid_loss      dur\n",
      "-------  ------------  -----------  ------------  -------\n",
      "      1        \u001b[36m2.2942\u001b[0m       \u001b[32m0.2290\u001b[0m        \u001b[35m2.2806\u001b[0m  40.7557\n",
      "      2        \u001b[36m2.2740\u001b[0m       \u001b[32m0.3230\u001b[0m        \u001b[35m2.2554\u001b[0m  39.4836\n",
      "      3        \u001b[36m2.2471\u001b[0m       \u001b[32m0.3689\u001b[0m        \u001b[35m2.2198\u001b[0m  39.4132\n",
      "      4        \u001b[36m2.2070\u001b[0m       \u001b[32m0.4113\u001b[0m        \u001b[35m2.1657\u001b[0m  39.4212\n",
      "      5        \u001b[36m2.1440\u001b[0m       \u001b[32m0.4294\u001b[0m        \u001b[35m2.0871\u001b[0m  39.4683\n",
      "  epoch    train_loss    valid_acc    valid_loss      dur\n",
      "-------  ------------  -----------  ------------  -------\n",
      "      1        \u001b[36m2.2956\u001b[0m       \u001b[32m0.1785\u001b[0m        \u001b[35m2.2861\u001b[0m  39.7190\n",
      "      2        \u001b[36m2.2812\u001b[0m       \u001b[32m0.2380\u001b[0m        \u001b[35m2.2688\u001b[0m  39.1334\n",
      "      3        \u001b[36m2.2639\u001b[0m       \u001b[32m0.2821\u001b[0m        \u001b[35m2.2460\u001b[0m  39.6059\n",
      "      4        \u001b[36m2.2405\u001b[0m       \u001b[32m0.3021\u001b[0m        \u001b[35m2.2154\u001b[0m  39.2758\n",
      "      5        \u001b[36m2.2051\u001b[0m       \u001b[32m0.3690\u001b[0m        \u001b[35m2.1694\u001b[0m  39.2189\n",
      "  epoch    train_loss    valid_acc    valid_loss      dur\n",
      "-------  ------------  -----------  ------------  -------\n",
      "      1        \u001b[36m2.2978\u001b[0m       \u001b[32m0.1787\u001b[0m        \u001b[35m2.2887\u001b[0m  39.7163\n",
      "      2        \u001b[36m2.2850\u001b[0m       \u001b[32m0.2797\u001b[0m        \u001b[35m2.2729\u001b[0m  39.4733\n",
      "      3        \u001b[36m2.2695\u001b[0m       \u001b[32m0.3417\u001b[0m        \u001b[35m2.2527\u001b[0m  39.3576\n",
      "      4        \u001b[36m2.2478\u001b[0m       \u001b[32m0.3640\u001b[0m        \u001b[35m2.2245\u001b[0m  39.1798\n",
      "      5        \u001b[36m2.2156\u001b[0m       \u001b[32m0.3735\u001b[0m        \u001b[35m2.1820\u001b[0m  38.9409\n",
      "  epoch    train_loss    valid_acc    valid_loss      dur\n",
      "-------  ------------  -----------  ------------  -------\n",
      "      1        \u001b[36m0.8759\u001b[0m       \u001b[32m0.7449\u001b[0m        \u001b[35m0.6698\u001b[0m  43.0148\n",
      "      2        \u001b[36m0.6309\u001b[0m       \u001b[32m0.7788\u001b[0m        \u001b[35m0.5670\u001b[0m  45.1326\n",
      "      3        \u001b[36m0.5656\u001b[0m       \u001b[32m0.8013\u001b[0m        \u001b[35m0.5299\u001b[0m  45.3229\n",
      "      4        \u001b[36m0.5198\u001b[0m       \u001b[32m0.8134\u001b[0m        \u001b[35m0.4957\u001b[0m  45.6874\n",
      "      5        \u001b[36m0.4830\u001b[0m       \u001b[32m0.8261\u001b[0m        \u001b[35m0.4638\u001b[0m  46.9254\n",
      "      6        \u001b[36m0.4610\u001b[0m       \u001b[32m0.8429\u001b[0m        \u001b[35m0.4244\u001b[0m  45.1276\n",
      "      7        \u001b[36m0.4331\u001b[0m       \u001b[32m0.8452\u001b[0m        \u001b[35m0.4224\u001b[0m  45.9001\n",
      "      8        \u001b[36m0.4180\u001b[0m       \u001b[32m0.8494\u001b[0m        \u001b[35m0.4062\u001b[0m  45.0031\n",
      "  epoch    train_loss    valid_acc    valid_loss      dur\n",
      "-------  ------------  -----------  ------------  -------\n",
      "      1        \u001b[36m0.8728\u001b[0m       \u001b[32m0.7416\u001b[0m        \u001b[35m0.6641\u001b[0m  42.1383\n",
      "      2        \u001b[36m0.6352\u001b[0m       \u001b[32m0.7809\u001b[0m        \u001b[35m0.5815\u001b[0m  44.5636\n",
      "      3        \u001b[36m0.5668\u001b[0m       \u001b[32m0.7959\u001b[0m        \u001b[35m0.5352\u001b[0m  45.5307\n",
      "      4        \u001b[36m0.5234\u001b[0m       \u001b[32m0.8216\u001b[0m        \u001b[35m0.4756\u001b[0m  45.1666\n",
      "      5        \u001b[36m0.4919\u001b[0m       \u001b[32m0.8233\u001b[0m        \u001b[35m0.4718\u001b[0m  45.1448\n",
      "      6        \u001b[36m0.4692\u001b[0m       \u001b[32m0.8427\u001b[0m        \u001b[35m0.4320\u001b[0m  44.3345\n",
      "      7        \u001b[36m0.4422\u001b[0m       \u001b[32m0.8471\u001b[0m        \u001b[35m0.4121\u001b[0m  45.1337\n",
      "      8        \u001b[36m0.4267\u001b[0m       0.8439        \u001b[35m0.4061\u001b[0m  44.3357\n",
      "  epoch    train_loss    valid_acc    valid_loss      dur\n",
      "-------  ------------  -----------  ------------  -------\n",
      "      1        \u001b[36m0.8717\u001b[0m       \u001b[32m0.7414\u001b[0m        \u001b[35m0.6871\u001b[0m  42.7119\n",
      "      2        \u001b[36m0.6227\u001b[0m       \u001b[32m0.7874\u001b[0m        \u001b[35m0.5622\u001b[0m  44.8329\n",
      "      3        \u001b[36m0.5503\u001b[0m       \u001b[32m0.8096\u001b[0m        \u001b[35m0.5142\u001b[0m  45.6825\n",
      "      4        \u001b[36m0.5051\u001b[0m       0.8039        0.5174  45.6670\n",
      "      5        \u001b[36m0.4753\u001b[0m       \u001b[32m0.8415\u001b[0m        \u001b[35m0.4327\u001b[0m  45.6127\n",
      "      6        \u001b[36m0.4467\u001b[0m       \u001b[32m0.8480\u001b[0m        \u001b[35m0.4110\u001b[0m  44.6700\n",
      "      7        \u001b[36m0.4317\u001b[0m       \u001b[32m0.8498\u001b[0m        \u001b[35m0.4028\u001b[0m  45.7312\n",
      "      8        \u001b[36m0.4125\u001b[0m       \u001b[32m0.8502\u001b[0m        \u001b[35m0.3985\u001b[0m  45.0725\n",
      "  epoch    train_loss    valid_acc    valid_loss      dur\n",
      "-------  ------------  -----------  ------------  -------\n",
      "      1        \u001b[36m0.8889\u001b[0m       \u001b[32m0.7445\u001b[0m        \u001b[35m0.6696\u001b[0m  42.4884\n",
      "      2        \u001b[36m0.6271\u001b[0m       \u001b[32m0.7626\u001b[0m        \u001b[35m0.5953\u001b[0m  43.2795\n",
      "      3        \u001b[36m0.5666\u001b[0m       \u001b[32m0.7967\u001b[0m        \u001b[35m0.5372\u001b[0m  46.2727\n",
      "      4        \u001b[36m0.5189\u001b[0m       \u001b[32m0.8183\u001b[0m        \u001b[35m0.4902\u001b[0m  89.6350\n"
     ]
    }
   ],
   "source": [
    "net = NeuralNetClassifier(\n",
    "    module=CNN,\n",
    "    max_epochs=5,\n",
    "    lr=0.001,\n",
    "    optimizer=optim.Adam,\n",
    "    criterion=nn.CrossEntropyLoss,\n",
    "    batch_size=64,\n",
    "    iterator_train__shuffle=True,\n",
    "    device='cuda' if torch.cuda.is_available() else 'cpu'\n",
    ")\n",
    "\n",
    "X = SliceDataset(train_dataset, idx=0)  #  image\n",
    "y = SliceDataset(train_dataset, idx=1)  #  label\n",
    "\n",
    "params = {\n",
    "    'lr': [0.001, 0.0005],\n",
    "    'max_epochs': [5, 8],\n",
    "    'module__dropout': [0.2, 0.4],\n",
    "    'optimizer': [optim.Adam, optim.SGD],\n",
    "    'optimizer__weight_decay': [0.0, 1e-4],\n",
    "}\n",
    "\n",
    "gs = GridSearchCV(\n",
    "    estimator=net,\n",
    "    param_grid=params,\n",
    "    refit=True,\n",
    "    cv=3,\n",
    "    scoring='accuracy',\n",
    "    n_jobs=1,\n",
    "    error_score='raise'  \n",
    ")\n",
    "\n",
    "gs.fit(X, y)\n",
    "\n",
    "print(\"Best CV score:\", gs.best_score_)\n",
    "print(\"Best params:\", gs.best_params_)\n",
    "\n",
    "best_net = gs.best_estimator_\n",
    "\n",
    "X_test = SliceDataset(test_dataset, idx=0)\n",
    "y_test = SliceDataset(test_dataset, idx=1)\n",
    "print(\"Test Accuracy:\", best_net.score(X_test, y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fb1dbd8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "724b840f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
